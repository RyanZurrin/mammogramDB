<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>omama.gp2.gp2.discriminators.base_cnn_discriminator API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>omama.gp2.gp2.discriminators.base_cnn_discriminator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .discriminator import Discriminator
from gp2.gp2.util import Util
from abc import ABC, abstractmethod

import numpy as np
import os
import pickle
import tensorflow as tf
from tensorflow.keras.layers import Layer
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint


class BaseCNNDiscriminator(Discriminator, ABC):
    &#34;&#34;&#34;
    Base class for CNN discriminators
    &#34;&#34;&#34;

    def __init__(self, workingdir=&#39;/tmp&#39;, verbose=True):
        super().__init__(workingdir)
        self.verbose = verbose

    @abstractmethod
    def create_convolution_layers(self, input_img, input_shape):
        pass

    @abstractmethod
    def build(self):
        pass

    def train(self, X_train_images, X_train_masks, y_train,
              X_val_images, X_val_masks, y_val,
              patience_counter=10, batch_size=64, epochs=100):
        &#34;&#34;&#34; Train the discriminator

        Args:
            X_train_images:  (np.ndarray) training images
            X_train_masks:  (np.ndarray) training masks
            y_train:  (np.ndarray) training labels
            X_val_images:  (np.ndarray) validation images
            X_val_masks:  (np.ndarray) validation masks
            y_val:  (np.ndarray) validation labels
            patience_counter:  (int) patience counter
            batch_size:  (int) batch size
            epochs:  (int) number of epochs

        Returns:
            None
        &#34;&#34;&#34;
        super().train(X_train_images, X_train_masks, y_train,
                      X_val_images, X_val_masks, y_val)
        checkpoint_file = os.path.join(self.workingdir, &#39;cnnd&#39;)
        checkpoint_file = Util.create_numbered_file(checkpoint_file, &#39;.model&#39;)

        callbacks = [EarlyStopping(patience=patience_counter,
                                   monitor=&#39;loss&#39;,
                                   verbose=0),
                     ModelCheckpoint(filepath=checkpoint_file,
                                     save_weights_only=False,
                                     monitor=&#39;val_loss&#39;,
                                     mode=&#39;min&#39;,
                                     verbose=0,
                                     save_best_only=True)]

        y_train = to_categorical(y_train)
        y_val = to_categorical(y_val)

        history = self.model.fit(x=[X_train_images, X_train_masks], y=y_train,
                                 batch_size=batch_size,
                                 epochs=epochs,
                                 callbacks=callbacks,
                                 validation_data=(
                                     [X_val_images, X_val_masks], y_val),
                                 verbose=0)

        history_file = os.path.join(self.workingdir, &#39;cnnd_history&#39;)
        history_file = Util.create_numbered_file(history_file, &#39;.pickle&#39;)

        with open(history_file, &#39;wb&#39;) as f:
            pickle.dump(history.history, f)

        print(&#39;Model saved to&#39;, checkpoint_file)
        print(&#39;History saved to&#39;, history_file)

    def predict(self, X_test_images, X_test_masks, y_test):
        &#34;&#34;&#34; Predict the labels for the test set

        Args:
            X_test_images: (np.ndarray) the test images
            X_test_masks:  (np.ndarray) the test masks
            y_test:  (np.ndarray) the test labels

        Returns:
            predictions: (np.ndarray) the predicted labels
        &#34;&#34;&#34;
        predictions = self.model.predict(x=[X_test_images, X_test_masks])

        # grab the most likely label from the categorical representation
        predictions = np.argmax(predictions, axis=-1)

        y_test = to_categorical(y_test)

        scores = self.model.evaluate(x=[X_test_images, X_test_masks], y=y_test)

        return predictions, scores


class CustomMaskLayer(Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def build(self, input_shape):
        self.mask = self.add_weight(name=&#39;mask&#39;,
                                    shape=input_shape[1:],
                                    initializer=tf.keras.initializers.Ones(),
                                    trainable=False)
        super().build(input_shape)

    def call(self, inputs):
        return inputs * self.mask

    def set_mask(self, mask):
        self.mask.assign(mask)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator"><code class="flex name class">
<span>class <span class="ident">BaseCNNDiscriminator</span></span>
<span>(</span><span>workingdir='/tmp', verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for CNN discriminators</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseCNNDiscriminator(Discriminator, ABC):
    &#34;&#34;&#34;
    Base class for CNN discriminators
    &#34;&#34;&#34;

    def __init__(self, workingdir=&#39;/tmp&#39;, verbose=True):
        super().__init__(workingdir)
        self.verbose = verbose

    @abstractmethod
    def create_convolution_layers(self, input_img, input_shape):
        pass

    @abstractmethod
    def build(self):
        pass

    def train(self, X_train_images, X_train_masks, y_train,
              X_val_images, X_val_masks, y_val,
              patience_counter=10, batch_size=64, epochs=100):
        &#34;&#34;&#34; Train the discriminator

        Args:
            X_train_images:  (np.ndarray) training images
            X_train_masks:  (np.ndarray) training masks
            y_train:  (np.ndarray) training labels
            X_val_images:  (np.ndarray) validation images
            X_val_masks:  (np.ndarray) validation masks
            y_val:  (np.ndarray) validation labels
            patience_counter:  (int) patience counter
            batch_size:  (int) batch size
            epochs:  (int) number of epochs

        Returns:
            None
        &#34;&#34;&#34;
        super().train(X_train_images, X_train_masks, y_train,
                      X_val_images, X_val_masks, y_val)
        checkpoint_file = os.path.join(self.workingdir, &#39;cnnd&#39;)
        checkpoint_file = Util.create_numbered_file(checkpoint_file, &#39;.model&#39;)

        callbacks = [EarlyStopping(patience=patience_counter,
                                   monitor=&#39;loss&#39;,
                                   verbose=0),
                     ModelCheckpoint(filepath=checkpoint_file,
                                     save_weights_only=False,
                                     monitor=&#39;val_loss&#39;,
                                     mode=&#39;min&#39;,
                                     verbose=0,
                                     save_best_only=True)]

        y_train = to_categorical(y_train)
        y_val = to_categorical(y_val)

        history = self.model.fit(x=[X_train_images, X_train_masks], y=y_train,
                                 batch_size=batch_size,
                                 epochs=epochs,
                                 callbacks=callbacks,
                                 validation_data=(
                                     [X_val_images, X_val_masks], y_val),
                                 verbose=0)

        history_file = os.path.join(self.workingdir, &#39;cnnd_history&#39;)
        history_file = Util.create_numbered_file(history_file, &#39;.pickle&#39;)

        with open(history_file, &#39;wb&#39;) as f:
            pickle.dump(history.history, f)

        print(&#39;Model saved to&#39;, checkpoint_file)
        print(&#39;History saved to&#39;, history_file)

    def predict(self, X_test_images, X_test_masks, y_test):
        &#34;&#34;&#34; Predict the labels for the test set

        Args:
            X_test_images: (np.ndarray) the test images
            X_test_masks:  (np.ndarray) the test masks
            y_test:  (np.ndarray) the test labels

        Returns:
            predictions: (np.ndarray) the predicted labels
        &#34;&#34;&#34;
        predictions = self.model.predict(x=[X_test_images, X_test_masks])

        # grab the most likely label from the categorical representation
        predictions = np.argmax(predictions, axis=-1)

        y_test = to_categorical(y_test)

        scores = self.model.evaluate(x=[X_test_images, X_test_masks], y=y_test)

        return predictions, scores</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="omama.gp2.gp2.discriminators.discriminator.Discriminator" href="discriminator.html#omama.gp2.gp2.discriminators.discriminator.Discriminator">Discriminator</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="omama.gp2.gp2.discriminators.cnn_discriminator_plus.CNNDiscriminatorPLUS" href="cnn_discriminator_plus.html#omama.gp2.gp2.discriminators.cnn_discriminator_plus.CNNDiscriminatorPLUS">CNNDiscriminatorPLUS</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def build(self):
    pass</code></pre>
</details>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.create_convolution_layers"><code class="name flex">
<span>def <span class="ident">create_convolution_layers</span></span>(<span>self, input_img, input_shape)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def create_convolution_layers(self, input_img, input_shape):
    pass</code></pre>
</details>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X_test_images, X_test_masks, y_test)</span>
</code></dt>
<dd>
<div class="desc"><p>Predict the labels for the test set</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X_test_images</code></strong></dt>
<dd>(np.ndarray) the test images</dd>
<dt><strong><code>X_test_masks</code></strong></dt>
<dd>(np.ndarray) the test masks</dd>
<dt><strong><code>y_test</code></strong></dt>
<dd>(np.ndarray) the test labels</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>predictions</code></dt>
<dd>(np.ndarray) the predicted labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X_test_images, X_test_masks, y_test):
    &#34;&#34;&#34; Predict the labels for the test set

    Args:
        X_test_images: (np.ndarray) the test images
        X_test_masks:  (np.ndarray) the test masks
        y_test:  (np.ndarray) the test labels

    Returns:
        predictions: (np.ndarray) the predicted labels
    &#34;&#34;&#34;
    predictions = self.model.predict(x=[X_test_images, X_test_masks])

    # grab the most likely label from the categorical representation
    predictions = np.argmax(predictions, axis=-1)

    y_test = to_categorical(y_test)

    scores = self.model.evaluate(x=[X_test_images, X_test_masks], y=y_test)

    return predictions, scores</code></pre>
</details>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, X_train_images, X_train_masks, y_train, X_val_images, X_val_masks, y_val, patience_counter=10, batch_size=64, epochs=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the discriminator</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X_train_images</code></strong></dt>
<dd>(np.ndarray) training images</dd>
<dt><strong><code>X_train_masks</code></strong></dt>
<dd>(np.ndarray) training masks</dd>
<dt><strong><code>y_train</code></strong></dt>
<dd>(np.ndarray) training labels</dd>
<dt><strong><code>X_val_images</code></strong></dt>
<dd>(np.ndarray) validation images</dd>
<dt><strong><code>X_val_masks</code></strong></dt>
<dd>(np.ndarray) validation masks</dd>
<dt><strong><code>y_val</code></strong></dt>
<dd>(np.ndarray) validation labels</dd>
<dt><strong><code>patience_counter</code></strong></dt>
<dd>(int) patience counter</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>(int) batch size</dd>
<dt><strong><code>epochs</code></strong></dt>
<dd>(int) number of epochs</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, X_train_images, X_train_masks, y_train,
          X_val_images, X_val_masks, y_val,
          patience_counter=10, batch_size=64, epochs=100):
    &#34;&#34;&#34; Train the discriminator

    Args:
        X_train_images:  (np.ndarray) training images
        X_train_masks:  (np.ndarray) training masks
        y_train:  (np.ndarray) training labels
        X_val_images:  (np.ndarray) validation images
        X_val_masks:  (np.ndarray) validation masks
        y_val:  (np.ndarray) validation labels
        patience_counter:  (int) patience counter
        batch_size:  (int) batch size
        epochs:  (int) number of epochs

    Returns:
        None
    &#34;&#34;&#34;
    super().train(X_train_images, X_train_masks, y_train,
                  X_val_images, X_val_masks, y_val)
    checkpoint_file = os.path.join(self.workingdir, &#39;cnnd&#39;)
    checkpoint_file = Util.create_numbered_file(checkpoint_file, &#39;.model&#39;)

    callbacks = [EarlyStopping(patience=patience_counter,
                               monitor=&#39;loss&#39;,
                               verbose=0),
                 ModelCheckpoint(filepath=checkpoint_file,
                                 save_weights_only=False,
                                 monitor=&#39;val_loss&#39;,
                                 mode=&#39;min&#39;,
                                 verbose=0,
                                 save_best_only=True)]

    y_train = to_categorical(y_train)
    y_val = to_categorical(y_val)

    history = self.model.fit(x=[X_train_images, X_train_masks], y=y_train,
                             batch_size=batch_size,
                             epochs=epochs,
                             callbacks=callbacks,
                             validation_data=(
                                 [X_val_images, X_val_masks], y_val),
                             verbose=0)

    history_file = os.path.join(self.workingdir, &#39;cnnd_history&#39;)
    history_file = Util.create_numbered_file(history_file, &#39;.pickle&#39;)

    with open(history_file, &#39;wb&#39;) as f:
        pickle.dump(history.history, f)

    print(&#39;Model saved to&#39;, checkpoint_file)
    print(&#39;History saved to&#39;, history_file)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer"><code class="flex name class">
<span>class <span class="ident">CustomMaskLayer</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the class from which all layers inherit.</p>
<p>A layer is a callable object that takes as input one or more tensors and
that outputs one or more tensors. It involves <em>computation</em>, defined
in the <code>call()</code> method, and a <em>state</em> (weight variables), defined
either in the constructor <code>__init__()</code> or in the <code>build()</code> method.</p>
<p>Users will just instantiate a layer and then treat it as a callable.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>trainable</code></strong></dt>
<dd>Boolean, whether the layer's variables should be trainable.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>String name of the layer.</dd>
<dt><strong><code>dtype</code></strong></dt>
<dd>The dtype of the layer's computations and weights. Can also be a
<code>tf.keras.mixed_precision.Policy</code>, which allows the computation and weight
dtype to differ. Default of <code>None</code> means to use
<code>tf.keras.mixed_precision.global_policy()</code>, which is a float32 policy
unless set to different value.</dd>
<dt><strong><code>dynamic</code></strong></dt>
<dd>Set this to <code>True</code> if your layer should only be run eagerly, and
should not be used to generate a static computation graph.
This would be the case for a Tree-RNN or a recursive network,
for example, or generally for any layer that manipulates tensors
using Python control flow. If <code>False</code>, we assume that the layer can
safely be used to generate a static computation graph.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>The name of the layer (string).</dd>
<dt><strong><code>dtype</code></strong></dt>
<dd>The dtype of the layer's weights.</dd>
<dt><strong><code>variable_dtype</code></strong></dt>
<dd>Alias of <code>dtype</code>.</dd>
<dt><strong><code>compute_dtype</code></strong></dt>
<dd>The dtype of the layer's computations. Layers automatically
cast inputs to this dtype which causes the computations and output to also
be in this dtype. When mixed precision is used with a
<code>tf.keras.mixed_precision.Policy</code>, this will be different than
<code>variable_dtype</code>.</dd>
<dt><strong><code>dtype_policy</code></strong></dt>
<dd>The layer's dtype policy. See the
<code>tf.keras.mixed_precision.Policy</code> documentation for details.</dd>
<dt><strong><code>trainable_weights</code></strong></dt>
<dd>List of variables to be included in backprop.</dd>
<dt><strong><code>non_trainable_weights</code></strong></dt>
<dd>List of variables that should not be
included in backprop.</dd>
<dt><strong><code>weights</code></strong></dt>
<dd>The concatenation of the lists trainable_weights and
non_trainable_weights (in this order).</dd>
<dt><strong><code>trainable</code></strong></dt>
<dd>Whether the layer should be trained (boolean), i.e. whether
its potentially-trainable weights should be returned as part of
<code>layer.trainable_weights</code>.</dd>
<dt><strong><code>input_spec</code></strong></dt>
<dd>Optional (list of) <code>InputSpec</code> object(s) specifying the
constraints on inputs that can be accepted by the layer.</dd>
</dl>
<p>We recommend that descendants of <code>Layer</code> implement the following methods:</p>
<ul>
<li><code>__init__()</code>: Defines custom layer attributes, and creates layer state
variables that do not depend on input shapes, using <code>add_weight()</code>.</li>
<li><code>build(self, input_shape)</code>: This method can be used to create weights that
depend on the shape(s) of the input(s), using <code>add_weight()</code>. <code>__call__()</code>
will automatically build the layer (if it has not been built yet) by
calling <code>build()</code>.</li>
<li><code>call(self, inputs, *args, **kwargs)</code>: Called in <code>__call__</code> after making
sure <code>build()</code> has been called. <code>call()</code> performs the logic of applying the
layer to the input tensors (which should be passed in as argument).
Two reserved keyword arguments you can optionally use in <code>call()</code> are:<ul>
<li><code>training</code> (boolean, whether the call is in inference mode or training
mode). See more details in <a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_training_argument_in_the_call_method">the layer/model subclassing guide</a></li>
<li><code>mask</code> (boolean tensor encoding masked timesteps in the input, used
in RNN layers). See more details in <a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_mask_argument_in_the_call_method">the layer/model subclassing guide</a>
A typical signature for this method is <code>call(self, inputs)</code>, and user could
optionally add <code>training</code> and <code>mask</code> if the layer need them. <code>*args</code> and
<code>**kwargs</code> is only useful for future extension when more input parameters
are planned to be added.</li>
</ul>
</li>
<li><code>get_config(self)</code>: Returns a dictionary containing the configuration used
to initialize this layer. If the keys differ from the arguments
in <code>__init__</code>, then override <code>from_config(self)</code> as well.
This method is used when saving
the layer or a model that contains this layer.</li>
</ul>
<p>Examples:</p>
<p>Here's a basic example: a layer with two variables, <code>w</code> and <code>b</code>,
that returns <code>y = w . x + b</code>.
It shows how to implement <code>build()</code> and <code>call()</code>.
Variables set as attributes of a layer are tracked as weights
of the layers (in <code>layer.weights</code>).</p>
<pre><code class="language-python">class SimpleDense(Layer):

  def __init__(self, units=32):
      super(SimpleDense, self).__init__()
      self.units = units

  def build(self, input_shape):  # Create the state of the layer (weights)
    w_init = tf.random_normal_initializer()
    self.w = tf.Variable(
        initial_value=w_init(shape=(input_shape[-1], self.units),
                             dtype='float32'),
        trainable=True)
    b_init = tf.zeros_initializer()
    self.b = tf.Variable(
        initial_value=b_init(shape=(self.units,), dtype='float32'),
        trainable=True)

  def call(self, inputs):  # Defines the computation from inputs to outputs
      return tf.matmul(inputs, self.w) + self.b

# Instantiates the layer.
linear_layer = SimpleDense(4)

# This will also call `build(input_shape)` and create the weights.
y = linear_layer(tf.ones((2, 2)))
assert len(linear_layer.weights) == 2

# These weights are trainable, so they're listed in `trainable_weights`:
assert len(linear_layer.trainable_weights) == 2
</code></pre>
<p>Note that the method <code>add_weight()</code> offers a shortcut to create weights:</p>
<pre><code class="language-python">class SimpleDense(Layer):

  def __init__(self, units=32):
      super(SimpleDense, self).__init__()
      self.units = units

  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)

  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b
</code></pre>
<p>Besides trainable weights, updated via backpropagation during training,
layers can also have non-trainable weights. These weights are meant to
be updated manually during <code>call()</code>. Here's a example layer that computes
the running sum of its inputs:</p>
<pre><code class="language-python">class ComputeSum(Layer):

  def __init__(self, input_dim):
      super(ComputeSum, self).__init__()
      # Create a non-trainable weight.
      self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),
                               trainable=False)

  def call(self, inputs):
      self.total.assign_add(tf.reduce_sum(inputs, axis=0))
      return self.total

my_sum = ComputeSum(2)
x = tf.ones((2, 2))

y = my_sum(x)
print(y.numpy())  # [2. 2.]

y = my_sum(x)
print(y.numpy())  # [4. 4.]

assert my_sum.weights == [my_sum.total]
assert my_sum.non_trainable_weights == [my_sum.total]
assert my_sum.trainable_weights == []
</code></pre>
<p>For more information about creating layers, see the guide
<a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Making new Layers and Models via subclassing</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomMaskLayer(Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def build(self, input_shape):
        self.mask = self.add_weight(name=&#39;mask&#39;,
                                    shape=input_shape[1:],
                                    initializer=tf.keras.initializers.Ones(),
                                    trainable=False)
        super().build(input_shape)

    def call(self, inputs):
        return inputs * self.mask

    def set_mask(self, mask):
        self.mask.assign(mask)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, input_shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <code>Layer</code> or <code>Model</code>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <code>Layer</code> subclasses.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_shape</code></strong></dt>
<dd>Instance of <code>TensorShape</code>, or list of instances of
<code>TensorShape</code> if the layer expects a list of inputs
(one instance per input).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, input_shape):
    self.mask = self.add_weight(name=&#39;mask&#39;,
                                shape=input_shape[1:],
                                initializer=tf.keras.initializers.Ones(),
                                trainable=False)
    super().build(input_shape)</code></pre>
</details>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, inputs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is where the layer's logic lives.</p>
<p>Note here that <code>call()</code> method in <code>tf.keras</code> is little bit different
from <code>keras</code> API. In <code>keras</code> API, you can pass support masking for
layers as additional arguments. Whereas <code>tf.keras</code> has <code>compute_mask()</code>
method to support masking.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs</code></strong></dt>
<dd>Input tensor, or list/tuple of input tensors.</dd>
<dt><strong><code>*args</code></strong></dt>
<dd>Additional positional arguments. Currently unused.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Additional keyword arguments. Currently unused.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tensor or list/tuple of tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def call(self, inputs):
    return inputs * self.mask</code></pre>
</details>
</dd>
<dt id="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.set_mask"><code class="name flex">
<span>def <span class="ident">set_mask</span></span>(<span>self, mask)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_mask(self, mask):
    self.mask.assign(mask)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="omama.gp2.gp2.discriminators" href="index.html">omama.gp2.gp2.discriminators</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator">BaseCNNDiscriminator</a></code></h4>
<ul class="">
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.build" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.build">build</a></code></li>
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.create_convolution_layers" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.create_convolution_layers">create_convolution_layers</a></code></li>
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.predict" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.predict">predict</a></code></li>
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.train" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.BaseCNNDiscriminator.train">train</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer">CustomMaskLayer</a></code></h4>
<ul class="">
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.build" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.build">build</a></code></li>
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.call" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.call">call</a></code></li>
<li><code><a title="omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.set_mask" href="#omama.gp2.gp2.discriminators.base_cnn_discriminator.CustomMaskLayer.set_mask">set_mask</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>
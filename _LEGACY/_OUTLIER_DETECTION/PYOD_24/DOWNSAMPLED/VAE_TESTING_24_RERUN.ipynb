{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0adee30",
   "metadata": {},
   "source": [
    "# VAE - Variational Auto Encoder\n",
    "### Variational auto encoder Encoder maps X onto a latent space Z Decoder samples Z from N(0,1) VAE_loss = Reconstruction_loss + KL_loss\n",
    "Source: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51813d2e",
   "metadata": {},
   "source": [
    "### Arguments that work with VAE algorithm:\n",
    "1. encoder_neurons\n",
    "2. oder_neurons\n",
    "3. ent_dim\n",
    "4. den_activation\n",
    "5. output_activation\n",
    "6. loss\n",
    "7. optimizer\n",
    "8. epochs\n",
    "9. batch_size\n",
    "10. dropout_rate\n",
    "11. l2_regularizer\n",
    "12. validation_size\n",
    "13. preprocessing\n",
    "14. verbose\n",
    "15. random_state\n",
    "16. contamination\n",
    "17. gamma\n",
    "18. capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa4da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0,'../../../..')\n",
    "import omama as O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fa73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get2D                    ...took   239.640712 seconds\n",
      "image downsampling       ...took     4.817800 seconds\n",
      "image downsampling       ...took     8.130872 seconds\n",
      "image downsampling       ...took    11.434571 seconds\n",
      "image downsampling       ...took    14.780524 seconds\n",
      "image downsampling       ...took    18.092300 seconds\n",
      "image downsampling       ...took    25.557104 seconds\n",
      "image downsampling       ...took    33.000907 seconds\n",
      "image downsampling       ...took    36.369237 seconds\n",
      "image downsampling       ...took    39.671978 seconds\n",
      "image downsampling       ...took    59.465349 seconds\n",
      "image downsampling       ...took    66.903264 seconds\n",
      "image downsampling       ...took    70.194269 seconds\n",
      "image downsampling       ...took    73.537665 seconds\n",
      "image downsampling       ...took    93.134808 seconds\n",
      "image downsampling       ...took    96.466756 seconds\n",
      "image downsampling       ...took    99.780026 seconds\n",
      "image downsampling       ...took   107.238756 seconds\n",
      "image downsampling       ...took   114.738510 seconds\n",
      "image downsampling       ...took   118.342615 seconds\n",
      "image downsampling       ...took   121.648301 seconds\n",
      "image downsampling       ...took   129.059687 seconds\n",
      "image downsampling       ...took   132.372004 seconds\n",
      "image downsampling       ...took   135.695747 seconds\n",
      "image downsampling       ...took   139.030896 seconds\n",
      "image downsampling       ...took   142.346439 seconds\n",
      "image downsampling       ...took   145.641168 seconds\n",
      "image downsampling       ...took   153.077221 seconds\n",
      "image downsampling       ...took   172.883873 seconds\n",
      "image downsampling       ...took   182.839065 seconds\n",
      "image downsampling       ...took   190.301284 seconds\n",
      "image downsampling       ...took   197.749300 seconds\n",
      "image downsampling       ...took   201.067182 seconds\n",
      "image downsampling       ...took   208.521238 seconds\n",
      "image downsampling       ...took   211.832450 seconds\n",
      "image downsampling       ...took   215.156342 seconds\n",
      "image downsampling       ...took   218.447950 seconds\n",
      "image downsampling       ...took   226.209154 seconds\n",
      "image downsampling       ...took   236.183069 seconds\n",
      "image downsampling       ...took   243.637240 seconds\n",
      "image downsampling       ...took   251.072592 seconds\n",
      "image downsampling       ...took   258.571342 seconds\n",
      "image downsampling       ...took   266.028524 seconds\n",
      "image downsampling       ...took   269.373698 seconds\n",
      "image downsampling       ...took   272.704530 seconds\n",
      "image downsampling       ...took   280.107097 seconds\n",
      "image downsampling       ...took   299.969566 seconds\n",
      "image downsampling       ...took   307.394511 seconds\n",
      "image downsampling       ...took   310.739292 seconds\n",
      "image downsampling       ...took   318.185206 seconds\n",
      "image downsampling       ...took   321.472225 seconds\n",
      "image downsampling       ...took   324.854577 seconds\n",
      "image downsampling       ...took   332.263454 seconds\n",
      "image downsampling       ...took   335.587847 seconds\n",
      "image downsampling       ...took   343.272422 seconds\n",
      "image downsampling       ...took   350.680066 seconds\n",
      "image downsampling       ...took   354.014139 seconds\n",
      "image downsampling       ...took   361.414566 seconds\n",
      "image downsampling       ...took   368.855699 seconds\n",
      "image downsampling       ...took   376.264012 seconds\n",
      "image downsampling       ...took   383.714676 seconds\n",
      "image downsampling       ...took   387.039497 seconds\n",
      "image downsampling       ...took   390.360141 seconds\n",
      "image downsampling       ...took   410.072145 seconds\n",
      "image downsampling       ...took   413.413943 seconds\n",
      "image downsampling       ...took   416.734161 seconds\n",
      "image downsampling       ...took   420.076515 seconds\n",
      "image downsampling       ...took   427.509354 seconds\n",
      "image downsampling       ...took   434.932800 seconds\n",
      "image downsampling       ...took   438.287200 seconds\n",
      "image downsampling       ...took   441.602357 seconds\n",
      "image downsampling       ...took   444.940479 seconds\n",
      "image downsampling       ...took   448.276515 seconds\n",
      "image downsampling       ...took   451.587425 seconds\n",
      "image downsampling       ...took   459.226847 seconds\n",
      "image downsampling       ...took   469.174717 seconds\n",
      "image downsampling       ...took   476.568453 seconds\n",
      "image downsampling       ...took   484.041278 seconds\n",
      "image downsampling       ...took   491.460209 seconds\n",
      "image downsampling       ...took   494.828515 seconds\n",
      "image downsampling       ...took   502.260171 seconds\n",
      "image downsampling       ...took   505.868526 seconds\n",
      "image downsampling       ...took   509.174737 seconds\n",
      "image downsampling       ...took   512.493771 seconds\n",
      "image downsampling       ...took   515.810369 seconds\n",
      "image downsampling       ...took   523.239819 seconds\n",
      "image downsampling       ...took   526.593934 seconds\n",
      "image downsampling       ...took   529.896301 seconds\n",
      "image downsampling       ...took   533.212022 seconds\n",
      "image downsampling       ...took   536.553859 seconds\n",
      "image downsampling       ...took   539.874583 seconds\n",
      "image downsampling       ...took   547.323907 seconds\n",
      "image downsampling       ...took   554.784524 seconds\n",
      "image downsampling       ...took   558.116517 seconds\n",
      "image downsampling       ...took   561.640535 seconds\n",
      "image downsampling       ...took   579.352849 seconds\n",
      "image downsampling       ...took   585.728592 seconds\n",
      "image downsampling       ...took   588.530818 seconds\n",
      "image downsampling       ...took   591.383811 seconds\n",
      "image downsampling       ...took   594.258295 seconds\n",
      "image downsampling       ...took   597.102341 seconds\n",
      "downsample               ...took   597.117662 seconds\n"
     ]
    }
   ],
   "source": [
    "imgs = O.DataHelper.get2D(N = 100, config_num=7, randomize=True, timing=True)\n",
    "downsampled_imgs = O.Normalize.downsample(imgs, output_shape=(64, 64), flatten=True, timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b376126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 00:44:35.213928: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-09-01 00:44:42.291660: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-01 00:44:42.480160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2022-09-01 00:44:42.480213: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-09-01 00:44:42.486638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-09-01 00:44:42.486678: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-09-01 00:44:42.489963: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-01 00:44:42.494523: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-01 00:44:42.504137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-09-01 00:44:42.508231: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-09-01 00:44:42.514587: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-09-01 00:44:42.549078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-09-01 00:44:42.549764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-01 00:44:42.565984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2022-09-01 00:44:42.613740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-09-01 00:44:42.613846: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-09-01 00:44:45.738989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-01 00:44:45.739047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-09-01 00:44:45.739053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-09-01 00:44:45.792712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 419 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4096)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         16781312    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          524416      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,316,196\n",
      "Trainable params: 17,316,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              528384    \n",
      "=================================================================\n",
      "Total params: 538,918\n",
      "Trainable params: 538,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4096)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              [(None, 2), (None, 2 17316196    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 4096)         538918      model[0][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         16781312    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          524416      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 2)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 2)            0           tf.__operators__.add[0][0]       \n",
      "                                                                 tf.math.square[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 2)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 2)            0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None,)              0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 4096)         0           model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 4096)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None,)              0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (None, 4096)         0           tf.convert_to_tensor[0][0]       \n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLambda) (None,)              0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None,)              0           tf.math.subtract_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None,)              0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None,)              0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb ()                   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 17,855,114\n",
      "Trainable params: 17,855,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 00:44:48.341886: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-01 00:44:48.363880: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245770000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 00:44:53.850591: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-09-01 00:44:57.012532: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-09-01 00:44:57.024208: W tensorflow/stream_executor/stream.cc:1455] attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas xGEMM launch failed : a.shape=[1,32,4096], b.shape=[1,4096,4096], m=32, n=4096, k=4096\n\t [[node model_2/dense/MatMul (defined at home/ryan.zurrin001/miniconda3/envs/O/lib/python3.9/site-packages/pyod/models/vae.py:341) ]] [Op:__inference_train_function_2576]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3239007/2128322167.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_scoresX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labelsX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mO\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutlierDetector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetect_outliers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdownsampled_imgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpyod_algorithm\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'VAE'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mO\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFeatures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview_image_and_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'downsample'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_scores\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_scoresX\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/omama/_EXPERIMENTS/OUTLIER_DETECTION/PYOD_20/DOWNSAMPLED/../../../../omama/outlier_detection/outlier_detector.py\u001B[0m in \u001B[0;36mdetect_outliers\u001B[0;34m(data_x, data_y, pyod_algorithm, activation_hidden, algorithm, alpha, approx_clf, approx_clf_list, approx_flag_global, approx_ng_clf_list, assume_centered, bandwidth, base_estimator, base_estimators, base_score, batch_size, behaviour, beta, booster, bootstrap, bootstrap_features, bps_flag, c, cache_size, capacity, check_detector, check_estimator, clustering_estimator, coef0, colsample_bylevel, colsample_bytree, combination, contamination, copy, cost_forecast_loc_fit, cost_forecast_loc_pred, covariance_type, D_layers, decay, decoder_neurons, degree, dis_measure, dropout_rate, encoder_neurons, epochs, epochs_query, eps, estimator_list, estimator_params, G_layers, gamma, hidden_activation, hidden_neurons, index_D_layer_for_recon_error, init_params, iterated_power, jl_method, kernel, l2_regularizer, latent_dim, latent_dim_G, leaf_size, learning_rate, learning_rate_query, loss, lr_d, lr_g, max_delta_step, max_depth, max_features, max_iter, max_samples, means_init, method, metric, metric_params, min_child_weight, momentum, n_bins, n_clusters, n_components, n_estimators, n_init, n_iter, n_jobs, n_neighbors, n_random_cuts, n_selected_components, novelty, nthread, nu, objective, optimizer, output_activation, p, parallel_execution, perplexity, precisions_init, preprocessing, radius, random_state, ref_set, reg_alpha, reg_covar, reg_lambda, rp_clf_list, rp_ng_clf_list, rp_flag_global, rule_of_thumb, scale_pos_weight, shrinking, silent, standardization, standardization_flag_list, stop_epochs, store_precision, subsample, subset_size, support_fraction, svd_solver, target_dim_frac, tol, use_ae, use_weights, validation_size, verbose, warm_start, weighted, weights_init, whiten, whitening)\u001B[0m\n\u001B[1;32m   1001\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1002\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdata_y\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1003\u001B[0;31m             \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1004\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1005\u001B[0m             \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/pyod/models/vae.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    339\u001B[0m         \u001B[0;31m# Build VAE model & fit with X\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    340\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 341\u001B[0;31m         self.history_ = self.model_.fit(X_norm,\n\u001B[0m\u001B[1;32m    342\u001B[0m                                         \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    343\u001B[0m                                         \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    948\u001B[0m         \u001B[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m         \u001B[0;31m# stateless function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 950\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    951\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    952\u001B[0m       \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInternalError\u001B[0m:  Blas xGEMM launch failed : a.shape=[1,32,4096], b.shape=[1,4096,4096], m=32, n=4096, k=4096\n\t [[node model_2/dense/MatMul (defined at home/ryan.zurrin001/miniconda3/envs/O/lib/python3.9/site-packages/pyod/models/vae.py:341) ]] [Op:__inference_train_function_2576]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train_scoresX, train_labelsX = O.OutlierDetector.detect_outliers(downsampled_imgs, pyod_algorithm='VAE')\n",
    "O.Features.view_image_and_features(imgs, ['downsample'], train_scores=[train_scoresX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a7823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

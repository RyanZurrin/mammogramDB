{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f700b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ac4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../..')\n",
    "import omama as O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000bf49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "odl = O.OutlierDetectorLite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f09d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_RUNS = 1\n",
    "DATASET = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26de3ab1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AE\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running AE...\n",
      "In AE algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:34:30.406680: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-15 17:34:31.536252: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-15 17:34:31.673665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-01-15 17:34:31.673712: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-15 17:34:31.677020: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-01-15 17:34:31.677058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-15 17:34:31.677943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-15 17:34:31.678281: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-15 17:34:31.678831: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-01-15 17:34:31.679621: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-01-15 17:34:31.679894: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-01-15 17:34:31.688316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                6168      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               6400      \n",
      "=================================================================\n",
      "Total params: 144,920\n",
      "Trainable params: 144,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:34:31.689001: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-15 17:34:31.693364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-01-15 17:34:31.701443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-01-15 17:34:31.701476: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-01-15 17:34:32.267092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-15 17:34:32.267140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-01-15 17:34:32.267146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-01-15 17:34:32.279441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38425 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0)\n",
      "2023-01-15 17:34:32.935608: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-01-15 17:34:32.955053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245755000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:34:33.553917: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 81ms/step - loss: 26.9545 - val_loss: 21.4898\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 19.5061 - val_loss: 18.8555\n",
      "Epoch 3/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.2908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:34:34.240452: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-01-15 17:34:34.240807: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 15.8488 - val_loss: 17.4570\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 13.7956 - val_loss: 16.6658\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 12.5928 - val_loss: 16.2227\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.7755 - val_loss: 15.9627\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.1256 - val_loss: 15.7710\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 10.6257 - val_loss: 15.6136\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 10.2026 - val_loss: 15.4783\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.8657 - val_loss: 15.3172\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.5621 - val_loss: 15.1276\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.3026 - val_loss: 15.0162\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.0540 - val_loss: 14.7985\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.8291 - val_loss: 14.5924\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.6443 - val_loss: 14.4436\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.4568 - val_loss: 14.2845\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.2725 - val_loss: 14.1278\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.1085 - val_loss: 13.9328\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.9464 - val_loss: 13.7629\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.7761 - val_loss: 13.5897\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.6250 - val_loss: 13.3775\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.4507 - val_loss: 13.2185\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 7.2408 - val_loss: 13.0275\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.0447 - val_loss: 12.8169\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.8570 - val_loss: 12.6370\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.6482 - val_loss: 12.4270\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.3329 - val_loss: 12.1652\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.1218 - val_loss: 11.8626\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.7952 - val_loss: 11.5516\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.5603 - val_loss: 11.2195\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.2597 - val_loss: 10.8767\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.8706 - val_loss: 10.5229\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.4822 - val_loss: 10.1910\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.2470 - val_loss: 9.8780\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.9200 - val_loss: 9.6031\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.7038 - val_loss: 9.3593\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.4814 - val_loss: 9.1606\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.3217 - val_loss: 8.9948\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.1597 - val_loss: 8.8742\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.1515 - val_loss: 8.7861\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.0126 - val_loss: 8.6946\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.9454 - val_loss: 8.6343\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.9234 - val_loss: 8.5880\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.7972 - val_loss: 8.5693\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.7502 - val_loss: 8.5249\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.7077 - val_loss: 8.4882\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.5984 - val_loss: 8.4435\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.5921 - val_loss: 8.3841\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.5694 - val_loss: 8.3616\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.5521 - val_loss: 8.3155\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.4686 - val_loss: 8.2755\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.4177 - val_loss: 8.2356\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3851 - val_loss: 8.1996\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3635 - val_loss: 8.1690\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3524 - val_loss: 8.1465\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2864 - val_loss: 8.1176\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2515 - val_loss: 8.0991\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2357 - val_loss: 8.0784\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2405 - val_loss: 8.0563\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1728 - val_loss: 8.0381\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1614 - val_loss: 8.0153\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1402 - val_loss: 8.0018\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1191 - val_loss: 7.9885\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0862 - val_loss: 7.9721\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1103 - val_loss: 7.9711\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0853 - val_loss: 7.9688\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0575 - val_loss: 7.9656\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0691 - val_loss: 7.9518\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.0177 - val_loss: 7.9396\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0244 - val_loss: 7.9241\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9856 - val_loss: 7.9131\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9855 - val_loss: 7.9103\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0079 - val_loss: 7.9014\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9343 - val_loss: 7.8975\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9252 - val_loss: 7.8892\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8969 - val_loss: 7.8783\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9007 - val_loss: 7.8785\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8652 - val_loss: 7.8757\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8827 - val_loss: 7.8796\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8955 - val_loss: 7.8774\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8709 - val_loss: 7.8825\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8522 - val_loss: 7.8755\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.8249 - val_loss: 7.8676\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8325 - val_loss: 7.8582\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8118 - val_loss: 7.8524\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8254 - val_loss: 7.8438\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8243 - val_loss: 7.8366\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8007 - val_loss: 7.8362\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7546 - val_loss: 7.8334\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7834 - val_loss: 7.8326\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7666 - val_loss: 7.8291\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7713 - val_loss: 7.8301\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7843 - val_loss: 7.8252\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7338 - val_loss: 7.8195\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7348 - val_loss: 7.8168\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7424 - val_loss: 7.8185\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7240 - val_loss: 7.8158\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7241 - val_loss: 7.8160\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7010 - val_loss: 7.8212\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7023 - val_loss: 7.8263\n",
      "len of imgs and t_scores are equal for AE\n",
      "Trained!\n",
      "AE 0.14285714285714285\n",
      "================================================================================\n",
      "Running AvgKNN\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running AvgKNN...\n",
      "In AvgKNN algorithm\n",
      "len of imgs and t_scores are equal for AvgKNN\n",
      "Trained!\n",
      "AvgKNN 0.0\n",
      "================================================================================\n",
      "Running VAE\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running VAE...\n",
      "In VAE algorithm\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            66          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            66          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 109,156\n",
      "Trainable params: 109,156\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               33024     \n",
      "=================================================================\n",
      "Total params: 43,558\n",
      "Trainable params: 43,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              [(None, 2), (None, 2 109156      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 256)          43558       model[0][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            66          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            66          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 2)            0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 2)            0           tf.__operators__.add[0][0]       \n",
      "                                                                 tf.math.square[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 2)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 2)            0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None,)              0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 256)          0           model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 256)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None,)              0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (None, 256)          0           tf.convert_to_tensor[0][0]       \n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLambda) (None,)              0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None,)              0           tf.math.subtract_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None,)              0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None,)              0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb ()                   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 152,714\n",
      "Trainable params: 152,714\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 88ms/step - loss: 306.5681 - val_loss: 507.0739\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 302.9339 - val_loss: 502.5628\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 303.8794 - val_loss: 500.0665\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 295.0974 - val_loss: 500.5294\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 292.8549 - val_loss: 498.2284\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 291.1826 - val_loss: 495.3192\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 287.5933 - val_loss: 494.5876\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 290.5490 - val_loss: 500.9896\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 280.7098 - val_loss: 493.9358\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 273.1041 - val_loss: 485.1953\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 260.1173 - val_loss: 485.7502\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 252.1346 - val_loss: 487.8255\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 245.0490 - val_loss: 479.6393\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 239.3059 - val_loss: 476.6312\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 238.4429 - val_loss: 475.6616\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 233.9503 - val_loss: 477.2311\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 229.8990 - val_loss: 483.5692\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 226.2446 - val_loss: 486.0088\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.7694 - val_loss: 491.6513\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 230.9534 - val_loss: 485.7827\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 230.0953 - val_loss: 485.4285\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 226.4291 - val_loss: 486.9102\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 229.6296 - val_loss: 493.0719\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 226.1026 - val_loss: 494.0533\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 227.0569 - val_loss: 483.1716\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 223.5451 - val_loss: 496.5097\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 232.2290 - val_loss: 495.4237\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 225.6786 - val_loss: 488.0572\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 231.5691 - val_loss: 494.8075\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.2163 - val_loss: 493.5669\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 231.7866 - val_loss: 495.9392\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 230.9214 - val_loss: 494.4971\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 232.4179 - val_loss: 496.0694\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 229.3915 - val_loss: 490.8123\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.6437 - val_loss: 487.2206\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 231.7126 - val_loss: 488.7960\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 229.0973 - val_loss: 496.3275\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 232.7149 - val_loss: 493.9167\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 232.1702 - val_loss: 487.9060\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 227.7795 - val_loss: 493.6690\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 226.7984 - val_loss: 495.1921\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 226.9277 - val_loss: 495.1558\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 230.7198 - val_loss: 494.1652\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.2507 - val_loss: 493.6698\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 232.4314 - val_loss: 494.9365\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 225.5598 - val_loss: 494.8856\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 225.6231 - val_loss: 494.0675\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 233.0381 - val_loss: 490.1034\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.8930 - val_loss: 496.4422\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 225.4486 - val_loss: 488.5293\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 227.1694 - val_loss: 496.3260\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 229.1721 - val_loss: 496.0711\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 224.6463 - val_loss: 496.2150\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.7598 - val_loss: 493.9514\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 227.4330 - val_loss: 497.9044\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 235.9843 - val_loss: 490.9859\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 225.5835 - val_loss: 491.5892\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 230.6236 - val_loss: 496.6601\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 229.2803 - val_loss: 495.9172\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 231.4031 - val_loss: 496.6085\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 231.3088 - val_loss: 494.2460\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.1836 - val_loss: 495.0647\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 227.9335 - val_loss: 495.2990\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 227.4283 - val_loss: 496.8399\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.8523 - val_loss: 495.5965\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 232.5052 - val_loss: 497.2024\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 230.8826 - val_loss: 495.2545\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.7009 - val_loss: 496.9578\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 232.5632 - val_loss: 491.7148\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.8362 - val_loss: 490.4506\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 234.8185 - val_loss: 494.2721\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 227.0646 - val_loss: 497.0150\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.8657 - val_loss: 491.2796\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.1574 - val_loss: 494.9452\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 228.0941 - val_loss: 494.9377\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 227.9526 - val_loss: 497.5318\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 228.8140 - val_loss: 496.9982\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 225.9714 - val_loss: 495.9894\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 228.4425 - val_loss: 486.4454\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 228.5117 - val_loss: 495.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 228.6581 - val_loss: 485.8917\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 231.7557 - val_loss: 497.0409\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 231.0319 - val_loss: 495.1439\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 229.0329 - val_loss: 490.9672\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 227.2700 - val_loss: 489.5952\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 234.1606 - val_loss: 496.7256\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 231.1970 - val_loss: 494.6552\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 232.1267 - val_loss: 496.9938\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 226.2015 - val_loss: 494.9138\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 228.0539 - val_loss: 496.0580\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 225.1059 - val_loss: 495.7845\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 228.7630 - val_loss: 495.7384\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 226.1110 - val_loss: 496.9121\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 226.5338 - val_loss: 497.2445\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 233.3988 - val_loss: 493.6710\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 231.4794 - val_loss: 496.8768\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 225.4445 - val_loss: 498.0711\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 231.6561 - val_loss: 489.5932\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 228.1613 - val_loss: 498.4904\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 227.3536 - val_loss: 494.3207\n",
      "len of imgs and t_scores are equal for VAE\n",
      "Trained!\n",
      "VAE 0.14285714285714285\n",
      "================================================================================\n",
      "Running SOGAAL\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running SOGAAL...\n",
      "In SOGAAL algorithm\n",
      "Epoch 1 of 60\n",
      "\n",
      "Testing for epoch 1 index 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel.haehn/miniconda3/envs/O/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 60\n",
      "\n",
      "Testing for epoch 2 index 1:\n",
      "Epoch 3 of 60\n",
      "\n",
      "Testing for epoch 3 index 1:\n",
      "Epoch 4 of 60\n",
      "\n",
      "Testing for epoch 4 index 1:\n",
      "Epoch 5 of 60\n",
      "\n",
      "Testing for epoch 5 index 1:\n",
      "Epoch 6 of 60\n",
      "\n",
      "Testing for epoch 6 index 1:\n",
      "Epoch 7 of 60\n",
      "\n",
      "Testing for epoch 7 index 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:45.207733: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.211771: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.243561: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.247501: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.279553: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.283470: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.315367: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.319297: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.369071: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.372976: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.410432: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.414533: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.446355: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.450277: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.481881: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.485793: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.517373: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.521321: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.554519: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.558427: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.591589: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.595479: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 60\n",
      "\n",
      "Testing for epoch 8 index 1:\n",
      "Epoch 9 of 60\n",
      "\n",
      "Testing for epoch 9 index 1:\n",
      "Epoch 10 of 60\n",
      "\n",
      "Testing for epoch 10 index 1:\n",
      "Epoch 11 of 60\n",
      "\n",
      "Testing for epoch 11 index 1:\n",
      "Epoch 12 of 60\n",
      "\n",
      "Testing for epoch 12 index 1:\n",
      "Epoch 13 of 60\n",
      "\n",
      "Testing for epoch 13 index 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:45.629796: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.633751: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.668812: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.672730: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.704379: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.708284: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.744738: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.748681: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.780420: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.784337: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.818288: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.822218: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 of 60\n",
      "\n",
      "Testing for epoch 14 index 1:\n",
      "Epoch 15 of 60\n",
      "\n",
      "Testing for epoch 15 index 1:\n",
      "Epoch 16 of 60\n",
      "\n",
      "Testing for epoch 16 index 1:\n",
      "Epoch 17 of 60\n",
      "\n",
      "Testing for epoch 17 index 1:\n",
      "Epoch 18 of 60\n",
      "\n",
      "Testing for epoch 18 index 1:\n",
      "Epoch 19 of 60\n",
      "\n",
      "Testing for epoch 19 index 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:45.874815: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.878772: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.911525: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.915450: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.968339: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:45.972485: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.004496: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 of 60\n",
      "\n",
      "Testing for epoch 20 index 1:\n",
      "Epoch 21 of 60\n",
      "\n",
      "Testing for epoch 21 index 1:\n",
      "Epoch 22 of 60\n",
      "\n",
      "Testing for epoch 22 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8721\n",
      "Epoch 23 of 60\n",
      "\n",
      "Testing for epoch 23 index 1:\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8870\n",
      "Epoch 24 of 60\n",
      "\n",
      "Testing for epoch 24 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8937\n",
      "Epoch 25 of 60\n",
      "\n",
      "Testing for epoch 25 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:46.126219: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.192682: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.262039: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 of 60\n",
      "\n",
      "Testing for epoch 26 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9142\n",
      "Epoch 27 of 60\n",
      "\n",
      "Testing for epoch 27 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9439\n",
      "Epoch 28 of 60\n",
      "\n",
      "Testing for epoch 28 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:46.331077: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.415540: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.482969: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 of 60\n",
      "\n",
      "Testing for epoch 29 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9948\n",
      "Epoch 30 of 60\n",
      "\n",
      "Testing for epoch 30 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9949\n",
      "Epoch 31 of 60\n",
      "\n",
      "Testing for epoch 31 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:46.556011: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.626216: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.711867: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 of 60\n",
      "\n",
      "Testing for epoch 32 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0255\n",
      "Epoch 33 of 60\n",
      "\n",
      "Testing for epoch 33 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0375\n",
      "Epoch 34 of 60\n",
      "\n",
      "Testing for epoch 34 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:46.784584: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.852707: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:46.921149: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 of 60\n",
      "\n",
      "Testing for epoch 35 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0565\n",
      "Epoch 36 of 60\n",
      "\n",
      "Testing for epoch 36 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0743\n",
      "Epoch 37 of 60\n",
      "\n",
      "Testing for epoch 37 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:46.990098: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.063255: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.152764: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 of 60\n",
      "\n",
      "Testing for epoch 38 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1110\n",
      "Epoch 39 of 60\n",
      "\n",
      "Testing for epoch 39 index 1:\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1346\n",
      "Epoch 40 of 60\n",
      "\n",
      "Testing for epoch 40 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:47.221169: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.307380: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.377811: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 of 60\n",
      "\n",
      "Testing for epoch 41 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1560\n",
      "Epoch 42 of 60\n",
      "\n",
      "Testing for epoch 42 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1611\n",
      "Epoch 43 of 60\n",
      "\n",
      "Testing for epoch 43 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:47.446849: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.514491: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.585765: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 of 60\n",
      "\n",
      "Testing for epoch 44 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1957\n",
      "Epoch 45 of 60\n",
      "\n",
      "Testing for epoch 45 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2122\n",
      "Epoch 46 of 60\n",
      "\n",
      "Testing for epoch 46 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:47.659750: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.727749: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.795067: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 of 60\n",
      "\n",
      "Testing for epoch 47 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2373\n",
      "Epoch 48 of 60\n",
      "\n",
      "Testing for epoch 48 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2504\n",
      "Epoch 49 of 60\n",
      "\n",
      "Testing for epoch 49 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:47.868325: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:47.936616: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.004380: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 of 60\n",
      "\n",
      "Testing for epoch 50 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2715\n",
      "Epoch 51 of 60\n",
      "\n",
      "Testing for epoch 51 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2999\n",
      "Epoch 52 of 60\n",
      "\n",
      "Testing for epoch 52 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:48.073145: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.144391: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.211999: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 of 60\n",
      "\n",
      "Testing for epoch 53 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3281\n",
      "Epoch 54 of 60\n",
      "\n",
      "Testing for epoch 54 index 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:48.281049: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.351885: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3291\n",
      "Epoch 55 of 60\n",
      "\n",
      "Testing for epoch 55 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3611\n",
      "Epoch 56 of 60\n",
      "\n",
      "Testing for epoch 56 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3550\n",
      "Epoch 57 of 60\n",
      "\n",
      "Testing for epoch 57 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:48.624170: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.691916: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.758843: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 of 60\n",
      "\n",
      "Testing for epoch 58 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3977\n",
      "Epoch 59 of 60\n",
      "\n",
      "Testing for epoch 59 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3960\n",
      "Epoch 60 of 60\n",
      "\n",
      "Testing for epoch 60 index 1:\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:36:48.832545: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.901257: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n",
      "2023-01-15 17:36:48.969546: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of imgs and t_scores are equal for SOGAAL\n",
      "Trained!\n",
      "SOGAAL 0.0\n",
      "================================================================================\n",
      "Running DeepSVDD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running DeepSVDD...\n",
      "In DeepSVDD algorithm\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                16384     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 32)                2048      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_4 (TFOpLamb (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_1 (TFOpLambda)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_3 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_2 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 18,432\n",
      "Trainable params: 18,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 20.0629 - val_loss: 9.6305\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 14.8019 - val_loss: 8.8913\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 11.9400 - val_loss: 8.3659\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 10.1688 - val_loss: 8.0297\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0708 - val_loss: 7.7335\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.3247 - val_loss: 7.4750\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6958 - val_loss: 7.2333\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2826 - val_loss: 7.0541\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7789 - val_loss: 6.9077\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4695 - val_loss: 6.7972\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.1388 - val_loss: 6.6963\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 5.8474 - val_loss: 6.5811\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5.5669 - val_loss: 6.4358\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5.3314 - val_loss: 6.3116\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5.1429 - val_loss: 6.1806\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4.9193 - val_loss: 6.0452\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.7367 - val_loss: 5.9225\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.5405 - val_loss: 5.8293\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.3891 - val_loss: 5.7194\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.2667 - val_loss: 5.6250\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.1435 - val_loss: 5.5389\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4.0017 - val_loss: 5.4620\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.8972 - val_loss: 5.3942\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.7917 - val_loss: 5.3625\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.6906 - val_loss: 5.3660\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.5700 - val_loss: 5.3793\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.4697 - val_loss: 5.3908\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.3727 - val_loss: 5.3885\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.2785 - val_loss: 5.3780\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.2046 - val_loss: 5.3841\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.1086 - val_loss: 5.4016\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.0260 - val_loss: 5.4257\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.9475 - val_loss: 5.4452\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.8702 - val_loss: 5.4811\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.7948 - val_loss: 5.5123\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.7217 - val_loss: 5.5488\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.6518 - val_loss: 5.6145\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5950 - val_loss: 5.6918\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5390 - val_loss: 5.7828\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.4743 - val_loss: 5.8640\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.4197 - val_loss: 5.8891\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.3767 - val_loss: 5.9308\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.3233 - val_loss: 5.9815\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2707 - val_loss: 6.0211\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.2288 - val_loss: 6.0884\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1791 - val_loss: 6.1911\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1347 - val_loss: 6.2863\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0969 - val_loss: 6.3372\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0612 - val_loss: 6.3331\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0292 - val_loss: 6.4197\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9977 - val_loss: 6.5207\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9501 - val_loss: 6.6108\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9197 - val_loss: 6.6462\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8868 - val_loss: 6.7038\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8579 - val_loss: 6.8045\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8349 - val_loss: 6.8516\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8064 - val_loss: 6.8788\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7793 - val_loss: 6.9392\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7553 - val_loss: 7.0580\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7320 - val_loss: 7.2393\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7048 - val_loss: 7.3966\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6703 - val_loss: 7.3969\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6523 - val_loss: 7.4673\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.6274 - val_loss: 7.5936\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6089 - val_loss: 7.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5906 - val_loss: 7.7789\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5671 - val_loss: 7.8929\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5507 - val_loss: 7.9864\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5358 - val_loss: 8.0217\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5132 - val_loss: 8.0940\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4984 - val_loss: 8.1963\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4799 - val_loss: 8.3305\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4637 - val_loss: 8.4442\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4470 - val_loss: 8.5045\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4350 - val_loss: 8.6459\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4158 - val_loss: 8.7616\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.4008 - val_loss: 8.8076\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3892 - val_loss: 8.9999\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3739 - val_loss: 9.1533\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3541 - val_loss: 9.2050\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3435 - val_loss: 9.3691\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3296 - val_loss: 9.5231\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3208 - val_loss: 9.6360\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3091 - val_loss: 9.6235\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2974 - val_loss: 9.7888\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2861 - val_loss: 9.9136\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2757 - val_loss: 9.9454\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2678 - val_loss: 10.1918\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2511 - val_loss: 10.2874\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2451 - val_loss: 10.4010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2352 - val_loss: 10.4404\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2245 - val_loss: 10.6648\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2182 - val_loss: 10.7882\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2083 - val_loss: 10.8759\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2030 - val_loss: 10.9642\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1941 - val_loss: 11.3167\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1876 - val_loss: 11.2407\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1797 - val_loss: 11.3560\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1714 - val_loss: 11.6445\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.1616 - val_loss: 11.6437\n",
      "len of imgs and t_scores are equal for DeepSVDD\n",
      "Trained!\n",
      "DeepSVDD 0.0\n",
      "================================================================================\n",
      "Running AnoGAN\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running AnoGAN...\n",
      "In AnoGAN algorithm\n",
      "Train iter:100\n",
      "Train iter:200\n",
      "Train iter:300\n",
      "Train iter:400\n",
      "query sample 1 / 100\n",
      "iter: 0\n",
      "query sample 2 / 100\n",
      "iter: 0\n",
      "query sample 3 / 100\n",
      "iter: 0\n",
      "query sample 4 / 100\n",
      "iter: 0\n",
      "query sample 5 / 100\n",
      "iter: 0\n",
      "query sample 6 / 100\n",
      "iter: 0\n",
      "query sample 7 / 100\n",
      "iter: 0\n",
      "query sample 8 / 100\n",
      "iter: 0\n",
      "query sample 9 / 100\n",
      "iter: 0\n",
      "query sample 10 / 100\n",
      "iter: 0\n",
      "query sample 11 / 100\n",
      "iter: 0\n",
      "query sample 12 / 100\n",
      "iter: 0\n",
      "query sample 13 / 100\n",
      "iter: 0\n",
      "query sample 14 / 100\n",
      "iter: 0\n",
      "query sample 15 / 100\n",
      "iter: 0\n",
      "query sample 16 / 100\n",
      "iter: 0\n",
      "query sample 17 / 100\n",
      "iter: 0\n",
      "query sample 18 / 100\n",
      "iter: 0\n",
      "query sample 19 / 100\n",
      "iter: 0\n",
      "query sample 20 / 100\n",
      "iter: 0\n",
      "query sample 21 / 100\n",
      "iter: 0\n",
      "query sample 22 / 100\n",
      "iter: 0\n",
      "query sample 23 / 100\n",
      "iter: 0\n",
      "query sample 24 / 100\n",
      "iter: 0\n",
      "query sample 25 / 100\n",
      "iter: 0\n",
      "query sample 26 / 100\n",
      "iter: 0\n",
      "query sample 27 / 100\n",
      "iter: 0\n",
      "query sample 28 / 100\n",
      "iter: 0\n",
      "query sample 29 / 100\n",
      "iter: 0\n",
      "query sample 30 / 100\n",
      "iter: 0\n",
      "query sample 31 / 100\n",
      "iter: 0\n",
      "query sample 32 / 100\n",
      "iter: 0\n",
      "query sample 33 / 100\n",
      "iter: 0\n",
      "query sample 34 / 100\n",
      "iter: 0\n",
      "query sample 35 / 100\n",
      "iter: 0\n",
      "query sample 36 / 100\n",
      "iter: 0\n",
      "query sample 37 / 100\n",
      "iter: 0\n",
      "query sample 38 / 100\n",
      "iter: 0\n",
      "query sample 39 / 100\n",
      "iter: 0\n",
      "query sample 40 / 100\n",
      "iter: 0\n",
      "query sample 41 / 100\n",
      "iter: 0\n",
      "query sample 42 / 100\n",
      "iter: 0\n",
      "query sample 43 / 100\n",
      "iter: 0\n",
      "query sample 44 / 100\n",
      "iter: 0\n",
      "query sample 45 / 100\n",
      "iter: 0\n",
      "query sample 46 / 100\n",
      "iter: 0\n",
      "query sample 47 / 100\n",
      "iter: 0\n",
      "query sample 48 / 100\n",
      "iter: 0\n",
      "query sample 49 / 100\n",
      "iter: 0\n",
      "query sample 50 / 100\n",
      "iter: 0\n",
      "query sample 51 / 100\n",
      "iter: 0\n",
      "query sample 52 / 100\n",
      "iter: 0\n",
      "query sample 53 / 100\n",
      "iter: 0\n",
      "query sample 54 / 100\n",
      "iter: 0\n",
      "query sample 55 / 100\n",
      "iter: 0\n",
      "query sample 56 / 100\n",
      "iter: 0\n",
      "query sample 57 / 100\n",
      "iter: 0\n",
      "query sample 58 / 100\n",
      "iter: 0\n",
      "query sample 59 / 100\n",
      "iter: 0\n",
      "query sample 60 / 100\n",
      "iter: 0\n",
      "query sample 61 / 100\n",
      "iter: 0\n",
      "query sample 62 / 100\n",
      "iter: 0\n",
      "query sample 63 / 100\n",
      "iter: 0\n",
      "query sample 64 / 100\n",
      "iter: 0\n",
      "query sample 65 / 100\n",
      "iter: 0\n",
      "query sample 66 / 100\n",
      "iter: 0\n",
      "query sample 67 / 100\n",
      "iter: 0\n",
      "query sample 68 / 100\n",
      "iter: 0\n",
      "query sample 69 / 100\n",
      "iter: 0\n",
      "query sample 70 / 100\n",
      "iter: 0\n",
      "query sample 71 / 100\n",
      "iter: 0\n",
      "query sample 72 / 100\n",
      "iter: 0\n",
      "query sample 73 / 100\n",
      "iter: 0\n",
      "query sample 74 / 100\n",
      "iter: 0\n",
      "query sample 75 / 100\n",
      "iter: 0\n",
      "query sample 76 / 100\n",
      "iter: 0\n",
      "query sample 77 / 100\n",
      "iter: 0\n",
      "query sample 78 / 100\n",
      "iter: 0\n",
      "query sample 79 / 100\n",
      "iter: 0\n",
      "query sample 80 / 100\n",
      "iter: 0\n",
      "query sample 81 / 100\n",
      "iter: 0\n",
      "query sample 82 / 100\n",
      "iter: 0\n",
      "query sample 83 / 100\n",
      "iter: 0\n",
      "query sample 84 / 100\n",
      "iter: 0\n",
      "query sample 85 / 100\n",
      "iter: 0\n",
      "query sample 86 / 100\n",
      "iter: 0\n",
      "query sample 87 / 100\n",
      "iter: 0\n",
      "query sample 88 / 100\n",
      "iter: 0\n",
      "query sample 89 / 100\n",
      "iter: 0\n",
      "query sample 90 / 100\n",
      "iter: 0\n",
      "query sample 91 / 100\n",
      "iter: 0\n",
      "query sample 92 / 100\n",
      "iter: 0\n",
      "query sample 93 / 100\n",
      "iter: 0\n",
      "query sample 94 / 100\n",
      "iter: 0\n",
      "query sample 95 / 100\n",
      "iter: 0\n",
      "query sample 96 / 100\n",
      "iter: 0\n",
      "query sample 97 / 100\n",
      "iter: 0\n",
      "query sample 98 / 100\n",
      "iter: 0\n",
      "query sample 99 / 100\n",
      "iter: 0\n",
      "query sample 100 / 100\n",
      "iter: 0\n",
      "len of imgs and t_scores are equal for AnoGAN\n",
      "Trained!\n",
      "AnoGAN 0.0\n",
      "================================================================================\n",
      "Running HBOS\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running HBOS...\n",
      "In HBOS algorithm\n",
      "len of imgs and t_scores are equal for HBOS\n",
      "Trained!\n",
      "HBOS 0.0\n",
      "================================================================================\n",
      "Running LOF\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running LOF...\n",
      "In LOF algorithm\n",
      "len of imgs and t_scores are equal for LOF\n",
      "Trained!\n",
      "LOF 0.45454545454545453\n",
      "================================================================================\n",
      "Running OCSVM\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running OCSVM...\n",
      "In OCSVM algorithm\n",
      "[LibSVM]*\n",
      "optimization finished, #iter = 50\n",
      "obj = 12.500000, rho = 0.500000\n",
      "nSV = 100, nBSV = 0\n",
      "len of imgs and t_scores are equal for OCSVM\n",
      "Trained!\n",
      "OCSVM 0.0\n",
      "================================================================================\n",
      "Running IForest\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running IForest...\n",
      "In IForest algorithm\n",
      "len of imgs and t_scores are equal for IForest\n",
      "Trained!\n",
      "IForest"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\n",
      "================================================================================\n",
      "Running CBLOF\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running CBLOF...\n",
      "In CBLOF algorithm\n",
      "len of imgs and t_scores are equal for CBLOF\n",
      "Trained!\n",
      "CBLOF 0.06666666666666667\n",
      "================================================================================\n",
      "Running COPOD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running COPOD...\n",
      "In COPOD algorithm\n",
      "len of imgs and t_scores are equal for COPOD\n",
      "Trained!\n",
      "COPOD 0.0\n",
      "================================================================================\n",
      "Running SOS\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running SOS...\n",
      "In SOS algorithm\n",
      "contamination:  0.08\n",
      "len of imgs and t_scores are equal for SOS\n",
      "Trained!\n",
      "SOS 0.3333333333333333\n",
      "================================================================================\n",
      "Running KDE\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running KDE...\n",
      "In KDE algorithm\n",
      "len of imgs and t_scores are equal for KDE\n",
      "Trained!\n",
      "KDE 0.0\n",
      "================================================================================\n",
      "Running Sampling\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running Sampling...\n",
      "In Sampling algorithm\n",
      "contamination:  0.08\n",
      "random_state: None\n",
      "len of imgs and t_scores are equal for Sampling\n",
      "Trained!\n",
      "Sampling 0.06666666666666667\n",
      "================================================================================\n",
      "Running PCA\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running PCA...\n",
      "In PCA algorithm\n",
      "len of imgs and t_scores are equal for PCA\n",
      "Trained!\n",
      "PCA 0.0\n",
      "================================================================================\n",
      "Running LMDD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running LMDD...\n",
      "In LMDD algorithm\n",
      "len of imgs and t_scores are equal for LMDD\n",
      "Trained!\n",
      "LMDD 0.0\n",
      "================================================================================\n",
      "Running COF\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running COF...\n",
      "In COF algorithm\n",
      "len of imgs and t_scores are equal for COF\n",
      "Trained!\n",
      "COF 0.06666666666666667\n",
      "================================================================================\n",
      "Running ECOD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running ECOD...\n",
      "In ECOD algorithm\n",
      "len of imgs and t_scores are equal for ECOD\n",
      "Trained!\n",
      "ECOD 0.0\n",
      "================================================================================\n",
      "Running KNN\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running KNN...\n",
      "In KNN algorithm\n",
      "KNN(algorithm='auto', contamination=0.08, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "  radius=1.0)\n",
      "len of imgs and t_scores are equal for KNN\n",
      "Trained!\n",
      "KNN 0.0\n",
      "================================================================================\n",
      "Running MedKNN\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running MedKNN...\n",
      "In MedKNN algorithm\n",
      "len of imgs and t_scores are equal for MedKNN\n",
      "Trained!\n",
      "MedKNN 0.0\n",
      "================================================================================\n",
      "Running SOD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running SOD...\n",
      "In SOD algorithm\n",
      "len of imgs and t_scores are equal for SOD\n",
      "Trained!\n",
      "SOD 0.23076923076923078\n",
      "================================================================================\n",
      "Running INNE\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running INNE...\n",
      "In INNE algorithm\n",
      "len of imgs and t_scores are equal for INNE\n",
      "Trained!\n",
      "INNE 0.3333333333333333\n",
      "================================================================================\n",
      "Running FB\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running FB...\n",
      "In FB algorithm\n",
      "len of imgs and t_scores are equal for FB\n",
      "Trained!\n",
      "FB 0.06666666666666667\n",
      "================================================================================\n",
      "Running LODA\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running LODA...\n",
      "In LODA algorithm\n",
      "len of imgs and t_scores are equal for LODA\n",
      "Trained!\n",
      "LODA 0.06666666666666667\n",
      "================================================================================\n",
      "Running SUOD\n",
      "Loaded images.\n",
      "Loaded config, norm, and feats.\n",
      "Calculated features!\n",
      "Running SUOD...\n",
      "In SUOD algorithm\n",
      "Worker 1 sum of ranks: 12.5\n",
      "\n",
      "Split among workers BPS: [0, 8, 8] [8, 0]\n",
      "Parallel Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Scheduling Total Train Time: 0.6410462856292725\n",
      "Split among workers default: [8] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of imgs and t_scores are equal for SUOD\n",
      "Trained!\n",
      "SUOD 0.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "runs = {}\n",
    "\n",
    "for algo in odl.ALGORITHMS:\n",
    "    \n",
    "    print('Running', algo)\n",
    "\n",
    "    runs[algo] = []\n",
    "    \n",
    "    for run in range(NO_RUNS):\n",
    "    \n",
    "        results = odl.run(DATASET, algo)\n",
    "        \n",
    "        print(algo, results['evaluation']['jaccard_score'])\n",
    "        \n",
    "        runs[algo].append(results)\n",
    "\n",
    "    print('='*80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79180193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE 0.14285714285714285 0.25 2\n",
      "AvgKNN 0.0 0.0 0\n",
      "VAE 0.14285714285714285 0.25 2\n",
      "SOGAAL 0.0 0.0 0\n",
      "DeepSVDD 0.0 0.0 0\n",
      "AnoGAN 0.0 0.0 0\n",
      "HBOS 0.0 0.0 0\n",
      "LOF 0.45454545454545453 0.625 5\n",
      "OCSVM 0.0 0.0 0\n",
      "IForest 0.0 0.0 0\n",
      "CBLOF 0.06666666666666667 0.125 1\n",
      "COPOD 0.0 0.0 0\n",
      "SOS 0.3333333333333333 0.5 4\n",
      "KDE 0.0 0.0 0\n",
      "Sampling 0.06666666666666667 0.125 1\n",
      "PCA 0.0 0.0 0\n",
      "LMDD 0.0 0.0 0\n",
      "COF 0.06666666666666667 0.125 1\n",
      "ECOD 0.0 0.0 0\n",
      "KNN 0.0 0.0 0\n",
      "MedKNN 0.0 0.0 0\n",
      "SOD 0.23076923076923078 0.375 3\n",
      "INNE 0.3333333333333333 0.5 4\n",
      "FB 0.06666666666666667 0.125 1\n",
      "LODA 0.06666666666666667 0.125 1\n",
      "SUOD 0.0 0.0 0\n"
     ]
    }
   ],
   "source": [
    "run = 0\n",
    "\n",
    "for algo in odl.ALGORITHMS:\n",
    "    \n",
    "    jaccard = runs[algo][run]['evaluation']['jaccard_score']\n",
    "    f1 = runs[algo][run]['evaluation']['f1']\n",
    "    tp = runs[algo][run]['evaluation']['tp']\n",
    "    \n",
    "    print(algo, jaccard, f1, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c34c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

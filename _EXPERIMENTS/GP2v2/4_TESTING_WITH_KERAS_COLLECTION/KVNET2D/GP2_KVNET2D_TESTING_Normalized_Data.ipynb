{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c4accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861fc4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.insert(0,'../../..')\n",
    "from omama import gp2\n",
    "from omama.gp2 import Runner\n",
    "from keras import losses, metrics\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e87808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KVNet2D in module gp2.gp2.classifiers.k_vnet2d:\n",
      "\n",
      "class KVNet2D(gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier)\n",
      " |  KVNet2D(input_size=(512, 512, 1), filter_num=None, n_labels=1, res_num_ini=1, res_num_max=2, activation='ReLU', output_activation='Sigmoid', batch_norm=True, pool=False, unpool=False, name='vnet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |  \n",
      " |  KVNet2D for binary segmentation\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KVNet2D\n",
      " |      gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier\n",
      " |      gp2.gp2.classifiers.classifier.Classifier\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_size=(512, 512, 1), filter_num=None, n_labels=1, res_num_ini=1, res_num_max=2, activation='ReLU', output_activation='Sigmoid', batch_norm=True, pool=False, unpool=False, name='vnet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |      vnet 2d\n",
      " |      \n",
      " |      vnet_2d(input_size, filter_num, n_labels,\n",
      " |              res_num_ini=1, res_num_max=3,\n",
      " |              activation='ReLU', output_activation='Softmax',\n",
      " |              batch_norm=False, pool=True, unpool=True, name='vnet')\n",
      " |      \n",
      " |      Milletari, F., Navab, N. and Ahmadi, S.A., 2016, October. V-net: Fully convolutional neural\n",
      " |      networks for volumetric medical image segmentation. In 2016 fourth international conference\n",
      " |      on 3D vision (3DV) (pp. 565-571). IEEE.\n",
      " |      \n",
      " |      The Two-dimensional version is inspired by:\n",
      " |      https://github.com/FENGShuanglang/2D-Vnet-Keras\n",
      " |      \n",
      " |      Input\n",
      " |      ----------\n",
      " |          input_size: the size/shape of network input, e.g., `(128, 128, 3)`.\n",
      " |          filter_num: a list that defines the number of filters for each                         down- and upsampling levels. e.g., `[64, 128, 256, 512]`.\n",
      " |                      The depth is expected as `len(filter_num)`.\n",
      " |          n_labels: number of output labels.\n",
      " |          res_num_ini: number of convolutional layers of the first first residual block (before downsampling).\n",
      " |          res_num_max: the max number of convolutional layers within a residual block.\n",
      " |          activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n",
      " |          output_activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interface or 'Sigmoid'.\n",
      " |                             Default option is 'Softmax'.\n",
      " |                             if None is received, then linear activation is applied.\n",
      " |          batch_norm: True for batch normalization.\n",
      " |          pool: True or 'max' for MaxPooling2D.\n",
      " |                'ave' for AveragePooling2D.\n",
      " |                False for strided conv + batch norm + activation.\n",
      " |          unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n",
      " |                  'nearest' for Upsampling2D with nearest interpolation.\n",
      " |                  False for Conv2DTranspose + batch norm + activation.\n",
      " |          name: prefix of the created keras layers.\n",
      " |      \n",
      " |      Output\n",
      " |      ----------\n",
      " |          model: a keras model.\n",
      " |      \n",
      " |      * This is a modified version of V-net for 2-d inputw.\n",
      " |      * The original work supports `pool=False` only.\n",
      " |        If pool is True, 'max', or 'ave', an additional conv2d layer will be applied.\n",
      " |      * All the 5-by-5 convolutional kernels are changed (and fixed) to 3-by-3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier:\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  build(self)\n",
      " |      Build the model.\n",
      " |  \n",
      " |  predict(self, X_test, y_pred, threshold=0.5)\n",
      " |      Predict the masks for the given images.\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_text : numpy.ndarray\n",
      " |          The images to predict the masks for.\n",
      " |      y_pred : numpy.ndarray\n",
      " |          The predicted masks.\n",
      " |      threshold : float\n",
      " |          The threshold to use for the predictions.\n",
      " |  \n",
      " |  train(self, X_train, y_train, X_val, y_val, patience_counter=2, batch_size=64, epochs=100, call_backs=None)\n",
      " |      Train the model.\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_train : numpy.ndarray\n",
      " |          The training images.\n",
      " |      y_train : numpy.ndarray\n",
      " |          The training masks.\n",
      " |      X_val : numpy.ndarray\n",
      " |          The validation images.\n",
      " |      y_val : numpy.ndarray\n",
      " |          The validation masks.\n",
      " |      patience_counter : int\n",
      " |          The number of epochs to wait before early stopping.\n",
      " |      batch_size : int\n",
      " |          The batch size to use.\n",
      " |      epochs : int\n",
      " |          The number of epochs to train for.\n",
      " |      call_backs : list\n",
      " |          The list of callbacks to use.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gp2.gp2.classifiers.classifier.Classifier:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gp2.KVNet2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc75325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** GP2  KVNet2D ***\n",
      "Working directory: /tmp/tmp0miwgh2nGP2\n",
      "Verbose mode active!\n",
      "{'verbose': True, 'workingdir': '/tmp/tmp0miwgh2nGP2', 'input_size': (512, 512, 1), 'filter_num': [16, 32, 64, 128], 'n_labels': 1, 'res_num_ini': 1, 'res_num_max': 2, 'activation': 'ReLU', 'output_activation': 'Sigmoid', 'batch_norm': True, 'pool': False, 'unpool': False, 'name': 'vnet', 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f224636b7c0>, 'loss': <function binary_crossentropy at 0x7f224667cd30>, 'metric': [<function Util.dice_coeff at 0x7f2246f94790>], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f22387c4d30>}\n",
      "Model summary:\n",
      "Model: \"vnet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0 (Conv2D)      (None, 512, 512, 16) 144         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0_bn (BatchNorm (None, 512, 512, 16) 64          vnet_input_conv_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0_activation (R (None, 512, 512, 16) 0           vnet_input_conv_0_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0 (Conv2D)          (None, 512, 512, 16) 2304        vnet_input_conv_0_activation[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0_bn (BatchNormaliz (None, 512, 512, 16) 64          vnet_down_0_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0_activation (ReLU) (None, 512, 512, 16) 0           vnet_down_0_0_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_add (Add)           (None, 512, 512, 16) 0           vnet_input_conv_0_activation[0][0\n",
      "                                                                 vnet_down_0_0_activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_add_activation (ReL (None, 512, 512, 16) 0           vnet_down_0_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_stride_conv  (None, 256, 256, 32) 2048        vnet_down_0_add_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_bn (BatchNor (None, 256, 256, 32) 128         vnet_down_1_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_activation ( (None, 256, 256, 32) 0           vnet_down_1_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0 (Conv2D) (None, 256, 256, 32) 9216        vnet_down_1_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0_bn (Batc (None, 256, 256, 32) 128         vnet_down_1_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0_activati (None, 256, 256, 32) 0           vnet_down_1_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1 (Conv2D) (None, 256, 256, 32) 9216        vnet_down_1_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1_bn (Batc (None, 256, 256, 32) 128         vnet_down_1_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1_activati (None, 256, 256, 32) 0           vnet_down_1_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_add (Add)  (None, 256, 256, 32) 0           vnet_down_1_encode_activation[0][\n",
      "                                                                 vnet_down_1_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_add_activa (None, 256, 256, 32) 0           vnet_down_1_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_stride_conv  (None, 128, 128, 64) 8192        vnet_down_1_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_bn (BatchNor (None, 128, 128, 64) 256         vnet_down_2_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_activation ( (None, 128, 128, 64) 0           vnet_down_2_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0 (Conv2D) (None, 128, 128, 64) 36864       vnet_down_2_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0_bn (Batc (None, 128, 128, 64) 256         vnet_down_2_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0_activati (None, 128, 128, 64) 0           vnet_down_2_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1 (Conv2D) (None, 128, 128, 64) 36864       vnet_down_2_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1_bn (Batc (None, 128, 128, 64) 256         vnet_down_2_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1_activati (None, 128, 128, 64) 0           vnet_down_2_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_add (Add)  (None, 128, 128, 64) 0           vnet_down_2_encode_activation[0][\n",
      "                                                                 vnet_down_2_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_add_activa (None, 128, 128, 64) 0           vnet_down_2_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_stride_conv  (None, 64, 64, 128)  32768       vnet_down_2_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_bn (BatchNor (None, 64, 64, 128)  512         vnet_down_3_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_activation ( (None, 64, 64, 128)  0           vnet_down_3_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0 (Conv2D) (None, 64, 64, 128)  147456      vnet_down_3_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0_bn (Batc (None, 64, 64, 128)  512         vnet_down_3_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0_activati (None, 64, 64, 128)  0           vnet_down_3_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1 (Conv2D) (None, 64, 64, 128)  147456      vnet_down_3_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1_bn (Batc (None, 64, 64, 128)  512         vnet_down_3_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1_activati (None, 64, 64, 128)  0           vnet_down_3_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_add (Add)  (None, 64, 64, 128)  0           vnet_down_3_encode_activation[0][\n",
      "                                                                 vnet_down_3_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_add_activa (None, 64, 64, 128)  0           vnet_down_3_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_trans_conv (Co (None, 128, 128, 64) 73792       vnet_down_3_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_bn (BatchNorma (None, 128, 128, 64) 256         vnet_up_0_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_activation (Re (None, 128, 128, 64) 0           vnet_up_0_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_concat (Concatenate)  (None, 128, 128, 128 0           vnet_up_0_decode_activation[0][0]\n",
      "                                                                 vnet_down_2_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0 (Conv2D)   (None, 128, 128, 64) 73728       vnet_up_0_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0_bn (BatchN (None, 128, 128, 64) 256         vnet_up_0_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0_activation (None, 128, 128, 64) 0           vnet_up_0_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1 (Conv2D)   (None, 128, 128, 64) 36864       vnet_up_0_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1_bn (BatchN (None, 128, 128, 64) 256         vnet_up_0_res_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1_activation (None, 128, 128, 64) 0           vnet_up_0_res_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_add (Add)    (None, 128, 128, 64) 0           vnet_up_0_decode_activation[0][0]\n",
      "                                                                 vnet_up_0_res_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_add_activati (None, 128, 128, 64) 0           vnet_up_0_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_trans_conv (Co (None, 256, 256, 32) 18464       vnet_up_0_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_bn (BatchNorma (None, 256, 256, 32) 128         vnet_up_1_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_activation (Re (None, 256, 256, 32) 0           vnet_up_1_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_concat (Concatenate)  (None, 256, 256, 64) 0           vnet_up_1_decode_activation[0][0]\n",
      "                                                                 vnet_down_1_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0 (Conv2D)   (None, 256, 256, 32) 18432       vnet_up_1_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0_bn (BatchN (None, 256, 256, 32) 128         vnet_up_1_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0_activation (None, 256, 256, 32) 0           vnet_up_1_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1 (Conv2D)   (None, 256, 256, 32) 9216        vnet_up_1_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1_bn (BatchN (None, 256, 256, 32) 128         vnet_up_1_res_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1_activation (None, 256, 256, 32) 0           vnet_up_1_res_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_add (Add)    (None, 256, 256, 32) 0           vnet_up_1_decode_activation[0][0]\n",
      "                                                                 vnet_up_1_res_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_add_activati (None, 256, 256, 32) 0           vnet_up_1_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_trans_conv (Co (None, 512, 512, 16) 4624        vnet_up_1_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_bn (BatchNorma (None, 512, 512, 16) 64          vnet_up_2_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_activation (Re (None, 512, 512, 16) 0           vnet_up_2_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_concat (Concatenate)  (None, 512, 512, 32) 0           vnet_up_2_decode_activation[0][0]\n",
      "                                                                 vnet_down_0_add_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0 (Conv2D)   (None, 512, 512, 16) 4608        vnet_up_2_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0_bn (BatchN (None, 512, 512, 16) 64          vnet_up_2_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0_activation (None, 512, 512, 16) 0           vnet_up_2_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_add (Add)    (None, 512, 512, 16) 0           vnet_up_2_decode_activation[0][0]\n",
      "                                                                 vnet_up_2_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_add_activati (None, 512, 512, 16) 0           vnet_up_2_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_output (Conv2D)            (None, 512, 512, 1)  17          vnet_up_2_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_output_activation (Activat (None, 512, 512, 1)  0           vnet_output[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 676,369\n",
      "Trainable params: 674,321\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n",
      "Using default discriminator (CNN)\n"
     ]
    }
   ],
   "source": [
    "R = Runner(verbose=True,\n",
    "           classifier='kvnet2d',\n",
    "           discriminator='cnn',\n",
    "           filter_num=[16, 32, 64, 128],\n",
    "           res_num_ini=1, \n",
    "           res_num_max=2, \n",
    "           activation='ReLU', \n",
    "           output_activation='Sigmoid', \n",
    "           batch_norm=True, \n",
    "           pool=False, \n",
    "           unpool=False,\n",
    "           optimizer=None, \n",
    "           loss=None, \n",
    "           metric=None,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b0c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our larger toy dataset (10k images and masks)\n",
    "images = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/gp2_ocular_normalized_images.npy')\n",
    "masks = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/gp2_ocular_normalized_masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7330ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:6000]\n",
    "masks = masks[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b4179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 512, 512, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57033c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 512, 512, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd71668",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'A': 0.5,\n",
    "    'A_train': 0.1,\n",
    "    'A_val': 0.3,\n",
    "    'A_test': 0.6,\n",
    "    'B': 0.3,\n",
    "    'B_train': 0.7,\n",
    "    'B_val': 0.1,\n",
    "    'B_test': 0.2,\n",
    "    'Z': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ff85c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights OK!\n",
      "******\n",
      "Loop 1\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 20s 3s/step - loss: 0.7740 - dice_coeff: 0.2021 - val_loss: 0.6782 - val_dice_coeff: 0.2400\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6108 - dice_coeff: 0.2863 - val_loss: 0.6673 - val_dice_coeff: 0.2453\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5055 - dice_coeff: 0.3682 - val_loss: 0.6490 - val_dice_coeff: 0.2507\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4284 - dice_coeff: 0.4457 - val_loss: 0.6310 - val_dice_coeff: 0.2539\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3617 - dice_coeff: 0.5245 - val_loss: 0.6143 - val_dice_coeff: 0.2557\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3107 - dice_coeff: 0.5957 - val_loss: 0.5984 - val_dice_coeff: 0.2568\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2762 - dice_coeff: 0.6481 - val_loss: 0.5824 - val_dice_coeff: 0.2579\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2590 - dice_coeff: 0.6772 - val_loss: 0.5662 - val_dice_coeff: 0.2590\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2509 - dice_coeff: 0.6988 - val_loss: 0.5498 - val_dice_coeff: 0.2597\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2388 - dice_coeff: 0.7132 - val_loss: 0.5344 - val_dice_coeff: 0.2601\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2379 - dice_coeff: 0.7188 - val_loss: 0.5200 - val_dice_coeff: 0.2602\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2290 - dice_coeff: 0.7265 - val_loss: 0.5058 - val_dice_coeff: 0.2604\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2265 - dice_coeff: 0.7317 - val_loss: 0.4920 - val_dice_coeff: 0.2600\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2233 - dice_coeff: 0.7366 - val_loss: 0.4779 - val_dice_coeff: 0.2589\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2210 - dice_coeff: 0.7410 - val_loss: 0.4643 - val_dice_coeff: 0.2592\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2259 - dice_coeff: 0.7396 - val_loss: 0.4527 - val_dice_coeff: 0.2590\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.2245 - dice_coeff: 0.7390 - val_loss: 0.4422 - val_dice_coeff: 0.2596\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_0vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_0.pkl\n",
      "Testing the classifier...\n",
      "****** TRAINING DISCRIMINATOR ******\n",
      "Model saved to /tmp/tmp0miwgh2nGP2/cnnd_0.model\n",
      "History saved to /tmp/tmp0miwgh2nGP2/cnnd_history_0.pickle\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 38ms/step - loss: 2.4708e-05 - accuracy: 1.0000\n",
      "Replacing 61 from 183 !\n",
      "D_relabeled_ 61\n",
      "point ids 61\n",
      "Removed: 61 Filled: 61\n",
      "TOOK 389.7197618484497 seconds\n",
      "==== DONE LOOP 1 ====\n",
      "******\n",
      "Loop 2\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.2098 - dice_coeff: 0.7466 - val_loss: 0.4309 - val_dice_coeff: 0.2587\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2104 - dice_coeff: 0.7468 - val_loss: 0.4222 - val_dice_coeff: 0.2546\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 5s 955ms/step - loss: 0.2096 - dice_coeff: 0.7462 - val_loss: 0.4131 - val_dice_coeff: 0.2524\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2114 - dice_coeff: 0.7467 - val_loss: 0.4040 - val_dice_coeff: 0.2533\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 6s 989ms/step - loss: 0.2097 - dice_coeff: 0.7464 - val_loss: 0.3967 - val_dice_coeff: 0.2534\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_1vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_1.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 5.1394e-05 - accuracy: 1.0000\n",
      "Replacing 62 from 187 !\n",
      "D_relabeled_ 62\n",
      "point ids 62\n",
      "Removed: 62 Filled: 62\n",
      "TOOK 117.16988825798035 seconds\n",
      "==== DONE LOOP 2 ====\n",
      "******\n",
      "Loop 3\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.2053 - dice_coeff: 0.7429 - val_loss: 0.3940 - val_dice_coeff: 0.2476\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 6s 950ms/step - loss: 0.2003 - dice_coeff: 0.7450 - val_loss: 0.3972 - val_dice_coeff: 0.2381\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 6s 891ms/step - loss: 0.2084 - dice_coeff: 0.7347 - val_loss: 0.3870 - val_dice_coeff: 0.2436\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 6s 910ms/step - loss: 0.2038 - dice_coeff: 0.7398 - val_loss: 0.3902 - val_dice_coeff: 0.2362\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_2vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_2.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 7.9764e-07 - accuracy: 1.0000\n",
      "Replacing 54 from 163 !\n",
      "D_relabeled_ 54\n",
      "point ids 54\n",
      "Removed: 54 Filled: 54\n",
      "TOOK 118.1869945526123 seconds\n",
      "==== DONE LOOP 3 ====\n",
      "******\n",
      "Loop 4\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1977 - dice_coeff: 0.7516 - val_loss: 0.4040 - val_dice_coeff: 0.2178\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 6s 835ms/step - loss: 0.1998 - dice_coeff: 0.7471 - val_loss: 0.4037 - val_dice_coeff: 0.2164\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 7s 867ms/step - loss: 0.1963 - dice_coeff: 0.7477 - val_loss: 0.4260 - val_dice_coeff: 0.1935\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 6s 838ms/step - loss: 0.1921 - dice_coeff: 0.7508 - val_loss: 0.4317 - val_dice_coeff: 0.1882\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 6s 838ms/step - loss: 0.1904 - dice_coeff: 0.7530 - val_loss: 0.4604 - val_dice_coeff: 0.1642\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 6s 835ms/step - loss: 0.1948 - dice_coeff: 0.7556 - val_loss: 0.4471 - val_dice_coeff: 0.1756\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 7s 875ms/step - loss: 0.1965 - dice_coeff: 0.7435 - val_loss: 0.4303 - val_dice_coeff: 0.1912\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_3vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_3.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 38ms/step - loss: 0.0108 - accuracy: 0.9972\n",
      "Replacing 59 from 177 !\n",
      "D_relabeled_ 59\n",
      "point ids 59\n",
      "Removed: 59 Filled: 59\n",
      "TOOK 118.46220636367798 seconds\n",
      "==== DONE LOOP 4 ====\n",
      "******\n",
      "Loop 5\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1951 - dice_coeff: 0.7571 - val_loss: 0.4444 - val_dice_coeff: 0.1804\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 7s 807ms/step - loss: 0.1969 - dice_coeff: 0.7580 - val_loss: 0.4336 - val_dice_coeff: 0.1902\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 7s 814ms/step - loss: 0.1995 - dice_coeff: 0.7505 - val_loss: 0.4521 - val_dice_coeff: 0.1772\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_4vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_4.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0027 - accuracy: 0.9972\n",
      "Replacing 58 from 176 !\n",
      "D_relabeled_ 58\n",
      "point ids 58\n",
      "Removed: 58 Filled: 58\n",
      "TOOK 76.03578972816467 seconds\n",
      "==== DONE LOOP 5 ====\n",
      "******\n",
      "Loop 6\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1933 - dice_coeff: 0.7553 - val_loss: 0.4670 - val_dice_coeff: 0.1676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 0.1879 - dice_coeff: 0.7614 - val_loss: 0.4846 - val_dice_coeff: 0.1600\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 7s 767ms/step - loss: 0.2011 - dice_coeff: 0.7455 - val_loss: 0.4615 - val_dice_coeff: 0.1827\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 0.1907 - dice_coeff: 0.7526 - val_loss: 0.4904 - val_dice_coeff: 0.1726\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_5vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_5.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0129 - accuracy: 0.9972\n",
      "Replacing 58 from 174 !\n",
      "D_relabeled_ 58\n",
      "point ids 58\n",
      "Removed: 58 Filled: 58\n",
      "TOOK 117.50663042068481 seconds\n",
      "==== DONE LOOP 6 ====\n",
      "******\n",
      "Loop 7\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 11s 987ms/step - loss: 0.1931 - dice_coeff: 0.7404 - val_loss: 0.4451 - val_dice_coeff: 0.2000\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 8s 742ms/step - loss: 0.1947 - dice_coeff: 0.7258 - val_loss: 0.4625 - val_dice_coeff: 0.2003\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 8s 742ms/step - loss: 0.1925 - dice_coeff: 0.7372 - val_loss: 0.4571 - val_dice_coeff: 0.2218\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 8s 743ms/step - loss: 0.1889 - dice_coeff: 0.7532 - val_loss: 0.4503 - val_dice_coeff: 0.2320\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 8s 744ms/step - loss: 0.1854 - dice_coeff: 0.7531 - val_loss: 0.4447 - val_dice_coeff: 0.2506\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 8s 785ms/step - loss: 0.1956 - dice_coeff: 0.7533 - val_loss: 0.4246 - val_dice_coeff: 0.2757\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 8s 748ms/step - loss: 0.1943 - dice_coeff: 0.7414 - val_loss: 0.3777 - val_dice_coeff: 0.3397\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_6vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_6.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 6.8761 - accuracy: 0.8583\n",
      "Replacing 48 from 145 !\n",
      "D_relabeled_ 48\n",
      "point ids 48\n",
      "Removed: 48 Filled: 48\n",
      "TOOK 178.5933814048767 seconds\n",
      "==== DONE LOOP 7 ====\n",
      "******\n",
      "Loop 8\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.1897 - dice_coeff: 0.7411 - val_loss: 0.3887 - val_dice_coeff: 0.3183\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 9s 798ms/step - loss: 0.1902 - dice_coeff: 0.7481 - val_loss: 0.3504 - val_dice_coeff: 0.3631\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 0.1863 - dice_coeff: 0.7508 - val_loss: 0.3535 - val_dice_coeff: 0.3777\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 9s 803ms/step - loss: 0.1875 - dice_coeff: 0.7440 - val_loss: 0.3365 - val_dice_coeff: 0.4052\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 9s 791ms/step - loss: 0.1829 - dice_coeff: 0.7564 - val_loss: 0.3213 - val_dice_coeff: 0.4237\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 9s 828ms/step - loss: 0.1829 - dice_coeff: 0.7495 - val_loss: 0.3150 - val_dice_coeff: 0.4512\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 0.1873 - dice_coeff: 0.7530 - val_loss: 0.2769 - val_dice_coeff: 0.4868\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 9s 822ms/step - loss: 0.1882 - dice_coeff: 0.7459 - val_loss: 0.2797 - val_dice_coeff: 0.5018\n",
      "Model saved to: /tmp/tmp0miwgh2nGP2/vnet_7vnet_model\n",
      "History saved to: /tmp/tmp0miwgh2nGP2/vnet_history_7.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 14.0085 - accuracy: 0.7694\n",
      "Replacing 33 from 101 !\n",
      "D_relabeled_ 33\n",
      "point ids 33\n",
      "Removed: 33 Filled: 33\n",
      "TOOK 179.34342050552368 seconds\n",
      "==== DONE LOOP 8 ====\n"
     ]
    }
   ],
   "source": [
    "R.run(images=images, masks=masks, weights=weights, runs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00075332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4424653649330139, 0.2733153700828552],\n",
       " [0.3980766534805298, 0.2643583118915558],\n",
       " [0.3950277268886566, 0.24495473504066467],\n",
       " [0.43985792994499207, 0.1918932944536209],\n",
       " [0.4618648588657379, 0.17477577924728394],\n",
       " [0.5184342861175537, 0.16016894578933716],\n",
       " [0.44070976972579956, 0.31046849489212036],\n",
       " [0.3380056619644165, 0.48392459750175476]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.classifier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35105656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.470823710609693e-05, 1.0],\n",
       " [5.139383574714884e-05, 1.0],\n",
       " [7.976366305229021e-07, 1.0],\n",
       " [0.01075794082134962, 0.9972222447395325],\n",
       " [0.002673221053555608, 0.9972222447395325],\n",
       " [0.01294263731688261, 0.9972222447395325],\n",
       " [6.876127243041992, 0.8583333492279053],\n",
       " [14.008524894714355, 0.769444465637207]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.discriminator_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256ed4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c83bb28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 240x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634bd3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c4accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861fc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.insert(0,'../../..')\n",
    "from omama import gp2\n",
    "from omama.gp2 import Runner\n",
    "from keras import losses, metrics\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e87808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KVNet2D in module gp2.gp2.classifiers.k_vnet2d:\n",
      "\n",
      "class KVNet2D(gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier)\n",
      " |  KVNet2D(input_size=(512, 512, 1), filter_num=None, n_labels=1, res_num_ini=1, res_num_max=2, activation='ReLU', output_activation='Sigmoid', batch_norm=True, pool=False, unpool=False, name='vnet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |  \n",
      " |  KVNet2D for binary segmentation\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KVNet2D\n",
      " |      gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier\n",
      " |      gp2.gp2.classifiers.classifier.Classifier\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_size=(512, 512, 1), filter_num=None, n_labels=1, res_num_ini=1, res_num_max=2, activation='ReLU', output_activation='Sigmoid', batch_norm=True, pool=False, unpool=False, name='vnet', optimizer=None, loss=None, metric=None, verbose=False, workingdir='/tmp')\n",
      " |      vnet 2d\n",
      " |      \n",
      " |      vnet_2d(input_size, filter_num, n_labels,\n",
      " |              res_num_ini=1, res_num_max=3,\n",
      " |              activation='ReLU', output_activation='Softmax',\n",
      " |              batch_norm=False, pool=True, unpool=True, name='vnet')\n",
      " |      \n",
      " |      Milletari, F., Navab, N. and Ahmadi, S.A., 2016, October. V-net: Fully convolutional neural\n",
      " |      networks for volumetric medical image segmentation. In 2016 fourth international conference\n",
      " |      on 3D vision (3DV) (pp. 565-571). IEEE.\n",
      " |      \n",
      " |      The Two-dimensional version is inspired by:\n",
      " |      https://github.com/FENGShuanglang/2D-Vnet-Keras\n",
      " |      \n",
      " |      Input\n",
      " |      ----------\n",
      " |          input_size: the size/shape of network input, e.g., `(128, 128, 3)`.\n",
      " |          filter_num: a list that defines the number of filters for each                         down- and upsampling levels. e.g., `[64, 128, 256, 512]`.\n",
      " |                      The depth is expected as `len(filter_num)`.\n",
      " |          n_labels: number of output labels.\n",
      " |          res_num_ini: number of convolutional layers of the first first residual block (before downsampling).\n",
      " |          res_num_max: the max number of convolutional layers within a residual block.\n",
      " |          activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interfaces, e.g., 'ReLU'.\n",
      " |          output_activation: one of the `tensorflow.keras.layers` or `keras_unet_collection.activations` interface or 'Sigmoid'.\n",
      " |                             Default option is 'Softmax'.\n",
      " |                             if None is received, then linear activation is applied.\n",
      " |          batch_norm: True for batch normalization.\n",
      " |          pool: True or 'max' for MaxPooling2D.\n",
      " |                'ave' for AveragePooling2D.\n",
      " |                False for strided conv + batch norm + activation.\n",
      " |          unpool: True or 'bilinear' for Upsampling2D with bilinear interpolation.\n",
      " |                  'nearest' for Upsampling2D with nearest interpolation.\n",
      " |                  False for Conv2DTranspose + batch norm + activation.\n",
      " |          name: prefix of the created keras layers.\n",
      " |      \n",
      " |      Output\n",
      " |      ----------\n",
      " |          model: a keras model.\n",
      " |      \n",
      " |      * This is a modified version of V-net for 2-d inputw.\n",
      " |      * The original work supports `pool=False` only.\n",
      " |        If pool is True, 'max', or 'ave', an additional conv2d layer will be applied.\n",
      " |      * All the 5-by-5 convolutional kernels are changed (and fixed) to 3-by-3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gp2.gp2.classifiers.base_keras_segmentation_classifier.BaseKerasSegmentationClassifier:\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  build(self)\n",
      " |      Build the model.\n",
      " |  \n",
      " |  predict(self, X_test, y_pred, threshold=0.5)\n",
      " |      Predict the masks for the given images.\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_text : numpy.ndarray\n",
      " |          The images to predict the masks for.\n",
      " |      y_pred : numpy.ndarray\n",
      " |          The predicted masks.\n",
      " |      threshold : float\n",
      " |          The threshold to use for the predictions.\n",
      " |  \n",
      " |  train(self, X_train, y_train, X_val, y_val, patience_counter=2, batch_size=64, epochs=100, call_backs=None)\n",
      " |      Train the model.\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X_train : numpy.ndarray\n",
      " |          The training images.\n",
      " |      y_train : numpy.ndarray\n",
      " |          The training masks.\n",
      " |      X_val : numpy.ndarray\n",
      " |          The validation images.\n",
      " |      y_val : numpy.ndarray\n",
      " |          The validation masks.\n",
      " |      patience_counter : int\n",
      " |          The number of epochs to wait before early stopping.\n",
      " |      batch_size : int\n",
      " |          The batch size to use.\n",
      " |      epochs : int\n",
      " |          The number of epochs to train for.\n",
      " |      call_backs : list\n",
      " |          The list of callbacks to use.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gp2.gp2.classifiers.classifier.Classifier:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gp2.KVNet2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc75325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** GP2  KVNet2D ***\n",
      "Working directory: /tmp/tmpd0resurkGP2\n",
      "Verbose mode active!\n",
      "{'verbose': True, 'workingdir': '/tmp/tmpd0resurkGP2', 'input_size': (512, 512, 1), 'filter_num': [16, 32, 64, 128, 256], 'n_labels': 1, 'res_num_ini': 1, 'res_num_max': 2, 'activation': 'ReLU', 'output_activation': 'Sigmoid', 'batch_norm': True, 'pool': False, 'unpool': False, 'name': 'vnet', 'optimizer': <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f9cf11e0b20>, 'loss': <function binary_crossentropy at 0x7f9d8ab48c10>, 'metric': [<function Util.dice_coeff at 0x7f9d8b460670>], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f8cc2106a30>}\n",
      "Model summary:\n",
      "Model: \"vnet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0 (Conv2D)      (None, 512, 512, 16) 144         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0_bn (BatchNorm (None, 512, 512, 16) 64          vnet_input_conv_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "vnet_input_conv_0_activation (R (None, 512, 512, 16) 0           vnet_input_conv_0_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0 (Conv2D)          (None, 512, 512, 16) 2304        vnet_input_conv_0_activation[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0_bn (BatchNormaliz (None, 512, 512, 16) 64          vnet_down_0_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_0_activation (ReLU) (None, 512, 512, 16) 0           vnet_down_0_0_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_add (Add)           (None, 512, 512, 16) 0           vnet_input_conv_0_activation[0][0\n",
      "                                                                 vnet_down_0_0_activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_0_add_activation (ReL (None, 512, 512, 16) 0           vnet_down_0_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_stride_conv  (None, 256, 256, 32) 2048        vnet_down_0_add_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_bn (BatchNor (None, 256, 256, 32) 128         vnet_down_1_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_encode_activation ( (None, 256, 256, 32) 0           vnet_down_1_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0 (Conv2D) (None, 256, 256, 32) 9216        vnet_down_1_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0_bn (Batc (None, 256, 256, 32) 128         vnet_down_1_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_0_activati (None, 256, 256, 32) 0           vnet_down_1_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1 (Conv2D) (None, 256, 256, 32) 9216        vnet_down_1_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1_bn (Batc (None, 256, 256, 32) 128         vnet_down_1_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_1_activati (None, 256, 256, 32) 0           vnet_down_1_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_add (Add)  (None, 256, 256, 32) 0           vnet_down_1_encode_activation[0][\n",
      "                                                                 vnet_down_1_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_1_res_conv_add_activa (None, 256, 256, 32) 0           vnet_down_1_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_stride_conv  (None, 128, 128, 64) 8192        vnet_down_1_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_bn (BatchNor (None, 128, 128, 64) 256         vnet_down_2_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_encode_activation ( (None, 128, 128, 64) 0           vnet_down_2_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0 (Conv2D) (None, 128, 128, 64) 36864       vnet_down_2_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0_bn (Batc (None, 128, 128, 64) 256         vnet_down_2_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_0_activati (None, 128, 128, 64) 0           vnet_down_2_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1 (Conv2D) (None, 128, 128, 64) 36864       vnet_down_2_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1_bn (Batc (None, 128, 128, 64) 256         vnet_down_2_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_1_activati (None, 128, 128, 64) 0           vnet_down_2_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_add (Add)  (None, 128, 128, 64) 0           vnet_down_2_encode_activation[0][\n",
      "                                                                 vnet_down_2_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_2_res_conv_add_activa (None, 128, 128, 64) 0           vnet_down_2_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_stride_conv  (None, 64, 64, 128)  32768       vnet_down_2_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_bn (BatchNor (None, 64, 64, 128)  512         vnet_down_3_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_encode_activation ( (None, 64, 64, 128)  0           vnet_down_3_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0 (Conv2D) (None, 64, 64, 128)  147456      vnet_down_3_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0_bn (Batc (None, 64, 64, 128)  512         vnet_down_3_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_0_activati (None, 64, 64, 128)  0           vnet_down_3_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1 (Conv2D) (None, 64, 64, 128)  147456      vnet_down_3_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1_bn (Batc (None, 64, 64, 128)  512         vnet_down_3_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_1_activati (None, 64, 64, 128)  0           vnet_down_3_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_add (Add)  (None, 64, 64, 128)  0           vnet_down_3_encode_activation[0][\n",
      "                                                                 vnet_down_3_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_3_res_conv_add_activa (None, 64, 64, 128)  0           vnet_down_3_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_encode_stride_conv  (None, 32, 32, 256)  131072      vnet_down_3_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_encode_bn (BatchNor (None, 32, 32, 256)  1024        vnet_down_4_encode_stride_conv[0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_encode_activation ( (None, 32, 32, 256)  0           vnet_down_4_encode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_0 (Conv2D) (None, 32, 32, 256)  589824      vnet_down_4_encode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_0_bn (Batc (None, 32, 32, 256)  1024        vnet_down_4_res_conv_0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_0_activati (None, 32, 32, 256)  0           vnet_down_4_res_conv_0_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_1 (Conv2D) (None, 32, 32, 256)  589824      vnet_down_4_res_conv_0_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_1_bn (Batc (None, 32, 32, 256)  1024        vnet_down_4_res_conv_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_1_activati (None, 32, 32, 256)  0           vnet_down_4_res_conv_1_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_add (Add)  (None, 32, 32, 256)  0           vnet_down_4_encode_activation[0][\n",
      "                                                                 vnet_down_4_res_conv_1_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_down_4_res_conv_add_activa (None, 32, 32, 256)  0           vnet_down_4_res_conv_add[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_trans_conv (Co (None, 64, 64, 128)  295040      vnet_down_4_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_bn (BatchNorma (None, 64, 64, 128)  512         vnet_up_0_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_decode_activation (Re (None, 64, 64, 128)  0           vnet_up_0_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_concat (Concatenate)  (None, 64, 64, 256)  0           vnet_up_0_decode_activation[0][0]\n",
      "                                                                 vnet_down_3_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0 (Conv2D)   (None, 64, 64, 128)  294912      vnet_up_0_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0_bn (BatchN (None, 64, 64, 128)  512         vnet_up_0_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_0_activation (None, 64, 64, 128)  0           vnet_up_0_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1 (Conv2D)   (None, 64, 64, 128)  147456      vnet_up_0_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1_bn (BatchN (None, 64, 64, 128)  512         vnet_up_0_res_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_1_activation (None, 64, 64, 128)  0           vnet_up_0_res_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_add (Add)    (None, 64, 64, 128)  0           vnet_up_0_decode_activation[0][0]\n",
      "                                                                 vnet_up_0_res_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_0_res_conv_add_activati (None, 64, 64, 128)  0           vnet_up_0_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_trans_conv (Co (None, 128, 128, 64) 73792       vnet_up_0_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_bn (BatchNorma (None, 128, 128, 64) 256         vnet_up_1_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_decode_activation (Re (None, 128, 128, 64) 0           vnet_up_1_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_concat (Concatenate)  (None, 128, 128, 128 0           vnet_up_1_decode_activation[0][0]\n",
      "                                                                 vnet_down_2_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0 (Conv2D)   (None, 128, 128, 64) 73728       vnet_up_1_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0_bn (BatchN (None, 128, 128, 64) 256         vnet_up_1_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_0_activation (None, 128, 128, 64) 0           vnet_up_1_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1 (Conv2D)   (None, 128, 128, 64) 36864       vnet_up_1_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1_bn (BatchN (None, 128, 128, 64) 256         vnet_up_1_res_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_1_activation (None, 128, 128, 64) 0           vnet_up_1_res_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_add (Add)    (None, 128, 128, 64) 0           vnet_up_1_decode_activation[0][0]\n",
      "                                                                 vnet_up_1_res_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_1_res_conv_add_activati (None, 128, 128, 64) 0           vnet_up_1_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_trans_conv (Co (None, 256, 256, 32) 18464       vnet_up_1_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_bn (BatchNorma (None, 256, 256, 32) 128         vnet_up_2_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_decode_activation (Re (None, 256, 256, 32) 0           vnet_up_2_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_concat (Concatenate)  (None, 256, 256, 64) 0           vnet_up_2_decode_activation[0][0]\n",
      "                                                                 vnet_down_1_res_conv_add_activati\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0 (Conv2D)   (None, 256, 256, 32) 18432       vnet_up_2_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0_bn (BatchN (None, 256, 256, 32) 128         vnet_up_2_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_0_activation (None, 256, 256, 32) 0           vnet_up_2_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_1 (Conv2D)   (None, 256, 256, 32) 9216        vnet_up_2_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_1_bn (BatchN (None, 256, 256, 32) 128         vnet_up_2_res_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_1_activation (None, 256, 256, 32) 0           vnet_up_2_res_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_add (Add)    (None, 256, 256, 32) 0           vnet_up_2_decode_activation[0][0]\n",
      "                                                                 vnet_up_2_res_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_2_res_conv_add_activati (None, 256, 256, 32) 0           vnet_up_2_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_decode_trans_conv (Co (None, 512, 512, 16) 4624        vnet_up_2_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_decode_bn (BatchNorma (None, 512, 512, 16) 64          vnet_up_3_decode_trans_conv[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_decode_activation (Re (None, 512, 512, 16) 0           vnet_up_3_decode_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_concat (Concatenate)  (None, 512, 512, 32) 0           vnet_up_3_decode_activation[0][0]\n",
      "                                                                 vnet_down_0_add_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_res_conv_0 (Conv2D)   (None, 512, 512, 16) 4608        vnet_up_3_concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_res_conv_0_bn (BatchN (None, 512, 512, 16) 64          vnet_up_3_res_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_res_conv_0_activation (None, 512, 512, 16) 0           vnet_up_3_res_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_res_conv_add (Add)    (None, 512, 512, 16) 0           vnet_up_3_decode_activation[0][0]\n",
      "                                                                 vnet_up_3_res_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "vnet_up_3_res_conv_add_activati (None, 512, 512, 16) 0           vnet_up_3_res_conv_add[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vnet_output (Conv2D)            (None, 512, 512, 1)  17          vnet_up_3_res_conv_add_activation\n",
      "__________________________________________________________________________________________________\n",
      "vnet_output_activation (Activat (None, 512, 512, 1)  0           vnet_output[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,729,105\n",
      "Trainable params: 2,724,753\n",
      "Non-trainable params: 4,352\n",
      "__________________________________________________________________________________________________\n",
      "Using default discriminator (CNN)\n"
     ]
    }
   ],
   "source": [
    "R = Runner(verbose=True,\n",
    "           classifier='kvnet2d',\n",
    "           discriminator='cnn',\n",
    "           filter_num=[16, 32, 64, 128, 256],\n",
    "           res_num_ini=1, \n",
    "           res_num_max=2, \n",
    "           activation='ReLU', \n",
    "           output_activation='Sigmoid', \n",
    "           batch_norm=True, \n",
    "           pool=False, \n",
    "           unpool=False,\n",
    "           optimizer=None, \n",
    "           loss=None, \n",
    "           metric=None,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b0c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our larger toy dataset (10k images and masks)\n",
    "images = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/gp2_ocular_unnormalized_images.npy')\n",
    "masks = np.load('/hpcstor6/scratch01/r/ryan.zurrin001/gp2_ocular_unnormalized_masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7330ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:6000]\n",
    "masks = masks[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5b4179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 512, 512, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57033c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 512, 512, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dd71668",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'A': 0.5,\n",
    "    'A_train': 0.1,\n",
    "    'A_val': 0.3,\n",
    "    'A_test': 0.6,\n",
    "    'B': 0.3,\n",
    "    'B_train': 0.7,\n",
    "    'B_val': 0.1,\n",
    "    'B_test': 0.2,\n",
    "    'Z': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ff85c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights OK!\n",
      "******\n",
      "Loop 1\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 1.2399 - dice_coeff: 0.3952 - val_loss: 2.6475 - val_dice_coeff: 0.3256\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 1.0085 - dice_coeff: 0.4207 - val_loss: 3.4765 - val_dice_coeff: 0.3221\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.8627 - dice_coeff: 0.4389 - val_loss: 5.1394 - val_dice_coeff: 0.3182\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7750 - dice_coeff: 0.4522 - val_loss: 6.5832 - val_dice_coeff: 0.3162\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7110 - dice_coeff: 0.4667 - val_loss: 7.2718 - val_dice_coeff: 0.3163\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6657 - dice_coeff: 0.4816 - val_loss: 7.4304 - val_dice_coeff: 0.3177\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6355 - dice_coeff: 0.4920 - val_loss: 7.3572 - val_dice_coeff: 0.3197\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6032 - dice_coeff: 0.4989 - val_loss: 7.0199 - val_dice_coeff: 0.3226\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5673 - dice_coeff: 0.5164 - val_loss: 6.6140 - val_dice_coeff: 0.3260\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5407 - dice_coeff: 0.5287 - val_loss: 6.0351 - val_dice_coeff: 0.3303\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5168 - dice_coeff: 0.5358 - val_loss: 5.5746 - val_dice_coeff: 0.3343\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4914 - dice_coeff: 0.5525 - val_loss: 5.2262 - val_dice_coeff: 0.3381\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4719 - dice_coeff: 0.5619 - val_loss: 4.8724 - val_dice_coeff: 0.3420\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4556 - dice_coeff: 0.5693 - val_loss: 4.5623 - val_dice_coeff: 0.3458\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4473 - dice_coeff: 0.5757 - val_loss: 4.3942 - val_dice_coeff: 0.3493\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4262 - dice_coeff: 0.5799 - val_loss: 4.0641 - val_dice_coeff: 0.3531\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4128 - dice_coeff: 0.5920 - val_loss: 3.9449 - val_dice_coeff: 0.3562\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.4021 - dice_coeff: 0.6000 - val_loss: 3.8331 - val_dice_coeff: 0.3593\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3938 - dice_coeff: 0.6045 - val_loss: 3.6384 - val_dice_coeff: 0.3627\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3862 - dice_coeff: 0.6102 - val_loss: 3.4141 - val_dice_coeff: 0.3665\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3808 - dice_coeff: 0.6103 - val_loss: 3.1287 - val_dice_coeff: 0.3706\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3839 - dice_coeff: 0.6084 - val_loss: 3.1402 - val_dice_coeff: 0.3739\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3703 - dice_coeff: 0.6159 - val_loss: 2.8422 - val_dice_coeff: 0.3785\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3676 - dice_coeff: 0.6183 - val_loss: 2.5364 - val_dice_coeff: 0.3831\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3603 - dice_coeff: 0.6224 - val_loss: 2.3536 - val_dice_coeff: 0.3872\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3610 - dice_coeff: 0.6247 - val_loss: 2.1740 - val_dice_coeff: 0.3914\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3590 - dice_coeff: 0.6213 - val_loss: 2.1866 - val_dice_coeff: 0.3947\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3579 - dice_coeff: 0.6261 - val_loss: 2.0820 - val_dice_coeff: 0.3988\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3534 - dice_coeff: 0.6233 - val_loss: 1.9025 - val_dice_coeff: 0.4034\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3459 - dice_coeff: 0.6301 - val_loss: 1.7205 - val_dice_coeff: 0.4079\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3482 - dice_coeff: 0.6336 - val_loss: 1.5562 - val_dice_coeff: 0.4123\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3423 - dice_coeff: 0.6343 - val_loss: 1.3807 - val_dice_coeff: 0.4167\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3414 - dice_coeff: 0.6340 - val_loss: 1.2187 - val_dice_coeff: 0.4209\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3368 - dice_coeff: 0.6367 - val_loss: 1.1208 - val_dice_coeff: 0.4248\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3380 - dice_coeff: 0.6405 - val_loss: 1.0644 - val_dice_coeff: 0.4284\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.3392 - dice_coeff: 0.6411 - val_loss: 0.9550 - val_dice_coeff: 0.4320\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_0vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_0.pkl\n",
      "Testing the classifier...\n",
      "****** TRAINING DISCRIMINATOR ******\n",
      "Model saved to /tmp/tmpd0resurkGP2/cnnd_0.model\n",
      "History saved to /tmp/tmpd0resurkGP2/cnnd_history_0.pickle\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.1076 - accuracy: 0.9917\n",
      "Replacing 63 from 191 !\n",
      "D_relabeled_ 63\n",
      "point ids 63\n",
      "Removed: 63 Filled: 63\n",
      "TOOK 407.92064213752747 seconds\n",
      "==== DONE LOOP 1 ====\n",
      "******\n",
      "Loop 2\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 11s 2s/step - loss: 0.3334 - dice_coeff: 0.6357 - val_loss: 0.8828 - val_dice_coeff: 0.4358\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3296 - dice_coeff: 0.6357 - val_loss: 0.8675 - val_dice_coeff: 0.4398\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3275 - dice_coeff: 0.6330 - val_loss: 0.8416 - val_dice_coeff: 0.4434\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3286 - dice_coeff: 0.6293 - val_loss: 0.7989 - val_dice_coeff: 0.4470\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3196 - dice_coeff: 0.6380 - val_loss: 0.7021 - val_dice_coeff: 0.4500\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3226 - dice_coeff: 0.6390 - val_loss: 0.6600 - val_dice_coeff: 0.4532\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3167 - dice_coeff: 0.6399 - val_loss: 0.6496 - val_dice_coeff: 0.4561\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3165 - dice_coeff: 0.6400 - val_loss: 0.6185 - val_dice_coeff: 0.4591\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3088 - dice_coeff: 0.6454 - val_loss: 0.5918 - val_dice_coeff: 0.4625\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3139 - dice_coeff: 0.6418 - val_loss: 0.5625 - val_dice_coeff: 0.4654\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3128 - dice_coeff: 0.6451 - val_loss: 0.5157 - val_dice_coeff: 0.4674\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_1vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_1.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 3.1409 - accuracy: 0.7222\n",
      "Replacing 28 from 85 !\n",
      "D_relabeled_ 28\n",
      "point ids 28\n",
      "Removed: 28 Filled: 28\n",
      "TOOK 236.9976246356964 seconds\n",
      "==== DONE LOOP 2 ====\n",
      "******\n",
      "Loop 3\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3097 - dice_coeff: 0.6418 - val_loss: 0.5116 - val_dice_coeff: 0.4710\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 6s 945ms/step - loss: 0.3101 - dice_coeff: 0.6358 - val_loss: 0.5041 - val_dice_coeff: 0.4741\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 6s 899ms/step - loss: 0.3089 - dice_coeff: 0.6272 - val_loss: 0.4775 - val_dice_coeff: 0.4750\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 6s 938ms/step - loss: 0.3047 - dice_coeff: 0.6375 - val_loss: 0.4922 - val_dice_coeff: 0.4766\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 6s 887ms/step - loss: 0.3065 - dice_coeff: 0.6331 - val_loss: 0.4893 - val_dice_coeff: 0.4800\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 6s 916ms/step - loss: 0.3021 - dice_coeff: 0.6351 - val_loss: 0.4804 - val_dice_coeff: 0.4829\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 6s 911ms/step - loss: 0.3017 - dice_coeff: 0.6414 - val_loss: 0.4574 - val_dice_coeff: 0.4855\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 6s 941ms/step - loss: 0.3010 - dice_coeff: 0.6474 - val_loss: 0.4138 - val_dice_coeff: 0.4883\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 6s 944ms/step - loss: 0.2972 - dice_coeff: 0.6451 - val_loss: 0.4006 - val_dice_coeff: 0.4910\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 6s 940ms/step - loss: 0.3026 - dice_coeff: 0.6421 - val_loss: 0.3898 - val_dice_coeff: 0.4932\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 7s 974ms/step - loss: 0.2919 - dice_coeff: 0.6531 - val_loss: 0.3750 - val_dice_coeff: 0.4954\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 0.2903 - dice_coeff: 0.6498 - val_loss: 0.3889 - val_dice_coeff: 0.4990\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 0.2890 - dice_coeff: 0.6538 - val_loss: 0.3850 - val_dice_coeff: 0.5005\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 6s 926ms/step - loss: 0.2867 - dice_coeff: 0.6553 - val_loss: 0.3618 - val_dice_coeff: 0.5009\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.2841 - dice_coeff: 0.6603 - val_loss: 0.3481 - val_dice_coeff: 0.5013\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2858 - dice_coeff: 0.6567 - val_loss: 0.3413 - val_dice_coeff: 0.5035\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2875 - dice_coeff: 0.6469 - val_loss: 0.4283 - val_dice_coeff: 0.5091\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_2vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_2.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 7.2241 - accuracy: 0.5639\n",
      "Replacing 8 from 24 !\n",
      "D_relabeled_ 8\n",
      "point ids 8\n",
      "Removed: 8 Filled: 8\n",
      "TOOK 296.38505578041077 seconds\n",
      "==== DONE LOOP 3 ====\n",
      "******\n",
      "Loop 4\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.2858 - dice_coeff: 0.6253 - val_loss: 0.4274 - val_dice_coeff: 0.5109\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2812 - dice_coeff: 0.6457 - val_loss: 0.3483 - val_dice_coeff: 0.5072\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 6s 944ms/step - loss: 0.2833 - dice_coeff: 0.6386 - val_loss: 0.3274 - val_dice_coeff: 0.5080\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2815 - dice_coeff: 0.6457 - val_loss: 0.3246 - val_dice_coeff: 0.5118\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_3vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_3.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 6.9906 - accuracy: 0.5639\n",
      "Replacing 9 from 28 !\n",
      "D_relabeled_ 9\n",
      "point ids 9\n",
      "Removed: 9 Filled: 9\n",
      "TOOK 116.41965436935425 seconds\n",
      "==== DONE LOOP 4 ====\n",
      "******\n",
      "Loop 5\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.2730 - dice_coeff: 0.6479 - val_loss: 0.3407 - val_dice_coeff: 0.5155\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 6s 971ms/step - loss: 0.2757 - dice_coeff: 0.6540 - val_loss: 0.3126 - val_dice_coeff: 0.5106\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 7s 980ms/step - loss: 0.2830 - dice_coeff: 0.6516 - val_loss: 0.3080 - val_dice_coeff: 0.5131\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_4vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_4.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 7.8799 - accuracy: 0.5750\n",
      "Replacing 10 from 30 !\n",
      "D_relabeled_ 10\n",
      "point ids 10\n",
      "Removed: 10 Filled: 10\n",
      "TOOK 119.13250279426575 seconds\n",
      "==== DONE LOOP 5 ====\n",
      "******\n",
      "Loop 6\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.2757 - dice_coeff: 0.6432 - val_loss: 0.3005 - val_dice_coeff: 0.5183\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2665 - dice_coeff: 0.6526 - val_loss: 0.2993 - val_dice_coeff: 0.5159\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.2699 - dice_coeff: 0.6462 - val_loss: 0.3006 - val_dice_coeff: 0.5132\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 0.2671 - dice_coeff: 0.6541 - val_loss: 0.2950 - val_dice_coeff: 0.5166\n",
      "Model saved to: /tmp/tmpd0resurkGP2/vnet_5vnet_model\n",
      "History saved to: /tmp/tmpd0resurkGP2/vnet_history_5.pkl\n",
      "Testing the classifier...\n",
      "Testing the discriminator...\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 24.0444 - accuracy: 0.4889\n",
      "No machine labels found. Skipping step 6.\n",
      "No more machine labels.\n",
      "TOOK 116.84997153282166 seconds\n"
     ]
    }
   ],
   "source": [
    "R.run(images=images, masks=masks, weights=weights, runs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6fd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00075332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8986756801605225, 0.4598231017589569],\n",
       " [0.49589967727661133, 0.5043867826461792],\n",
       " [0.38676050305366516, 0.5452563762664795],\n",
       " [0.3203839361667633, 0.5485392212867737],\n",
       " [0.30790042877197266, 0.5485397577285767],\n",
       " [0.29797691106796265, 0.5517064332962036]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.classifier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35105656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10757982730865479, 0.9916666746139526],\n",
       " [3.1409430503845215, 0.7222222089767456],\n",
       " [7.224101543426514, 0.5638889074325562],\n",
       " [6.990585803985596, 0.5638889074325562],\n",
       " [7.8798604011535645, 0.574999988079071],\n",
       " [24.044387817382812, 0.4888888895511627]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.discriminator_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256ed4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c83bb28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOgAAADoCAYAAADlqah4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAxOAAAMTgF/d4wjAAAstUlEQVR4nO2dd3hUVfrHPzOpkIQQQk8CAQPeS4AECChlERAbKiAEUFZAFrG76y64Ivpzzyq6uiq6NrCtggU1VEHUlabSpEqRO1QhoUcggQCpM78/7iSGkDI3mZk7yZzP88yT3Pq+k8x3zjnvPed9LQ6HA4lE4ptYzXZAIpFUjBSoROLDSIFKJD6MFKhE4sNIgUokPowUqETiw0iBSiQ+TKDZDniCkJAQR5MmTSo8XlRUREBAgBc9kral7fI5cuRIvsPhCKnouCkC1RT1NWAw0BropNq0nRWcNwGYgt7SLwceUG1aYVX3b9KkCYcPH67weEZGBnFxcdVxvcZI29J2aSwWS2Zl15vVxZ0L9AEOVXSCpqhtgGec5yUAzYEJXvFOIvERTBGoatN+UG1axU2cTiqwQLVpJ1Sb5gBmAnd43juJxHfw5SBRKy5tYQ8690kkfoOvB4lKz+S3VHSSxWL5G/C34u2IiAgyMjIqvOnp06fd4lx1qK5tdyxqOH36tFvuI20bs10TfFmg6UB8qe3Wzn2X4XA4pgPTi7djY2MdFQ3MHQ4HBUV204IGgCHb+fn5pKenU1BQUGO7AQEBnD9/vsb3kbaN2c7Ly6NVq1YEBwcbvt6XBToPWK0p6tPASeA+4LOa3PDX387zpw83cn1CBI/Ht3aHjx4nPT2diIgIoqOjsVgq7ES4REFBAUFBQW7yTNp2hfz8fM6ePUt6ejoJCQmGrzfrMcubwBD0yOwyTVFzVJuWoCnqe8CXqk37UrVpBzRF/QewBn2svAJ4vyZ2YxrW4+zFAr7STjNliKPGH3hPY7fbKSgoIDo6msDAmv+rfPl5YF21HRAQQHR0NKdPn8Zut2O1Ggv7mCJQ1aY9CDxYzv67y2y/C7zrLrvBgVZu6xLDe6t/ZePBM/Ro08hdt/YIxeMmX/8ikVRO8f+vOuNgX47ieoRR3fXx3+cbKw4iSSqnsLCQp59+GkVRSExMRFEU7rnnHhYuXEhKSorb7Q0aNIj9+/cDsH//frp27UqXLl344IMPuPvuu/nxxx/dbtNX8OUxqEdo1yyCxGb1WbrjGGJwByJCzRmb1GYmTJjA6dOnWbduHVFRUdjtdubNm+ex6PjSpUtLfp87dy49e/bkzTffBGD8+PGG71dYWOiWIYM38LsWFODmDlFcLChi8bZjZrtS69i3bx9paWl88MEHREVFAWC1WhkxYgRt27YtOa+wsJAbbriBlJQUEhMTGTduHBcuXABg/fr1dOvWjeTkZDp27MiMGTMAeO+99+jQoQPJycl06tSJn376CYD4+Hh27tzJ7NmzeeWVV0hLSyM5OZldu3bRr18/lixZAsC5c+eYOHEiPXr0oHPnztx3330l0e9+/frxxBNPcO2113LDDTd47e9VU2rH14ibuTahIa+vPs7nmzIYfVXtmfuQcf8D5GeU+6TJJRyOigNjwXGtiJvxVpX32LJlC+3ataNx48aVnhcQEMCnn35KdHQ0DoeDe++9l7feeovJkyfzr3/9i0mTJjF69GgAzpw5A8CkSZPQNI2WLVtSUFBAXl7eJfccO3YsBw4cICcnh5deeukym5MmTaJv3768++67OBwOJk6cyBtvvMGDD+rhjp9//plvvvnGtIhudfBLgdYPDuDmzi2Yu/kwu4+f48rmEWa7VOdwOBy88sorfPXVVxQWFpKdnV3Sgvbv359p06axb98+BgwYQJ8+fQAYMGAAY8eO5dZbb+Wmm26iffv2hmwuXLiQ9evX8/LLLwNw8eLFS549jhkzplaJE/xUoKAHi+ZuPsznGzN46tYOZrvjEq60cJWRn59frYflpenatSt79+7l1KlTREdHV3jep59+yvfff88PP/xAREQE06dPZ+3atQA88sgjDB48mOXLlzN16lQ6duzIW2+9xfz589m8eTOrVq1i0KBBTJs2jdtvv91l3xwOBwsXLrykqw36+wYIDw+vxjs2F78cgwKktI6ibZMwFmw9TF5hkdnu1BoSEhIYPnw4EyZMICsrC9CFMXv27JJIK+jd1ujoaCIiIjh37hwfffRRybHdu3fTtm1bJk6cyNSpU1m/fj2FhYXs37+flJQUJk+eTGpqKhs2bDDk2+DBg3n++ecpLCws8WHfvn01f9Mm4rcCtVgsjEyJ48yFApZrJ812p1bx3//+l6SkJK666ioSExNJTExk7dq1l7SoY8eOJScnhw4dOjBs2DB69+5dcuz1118nMTGRLl268OSTT/Lyyy9TVFTE+PHj6dixI8nJyWzevJm//e1v5ZmvkFdffZXAwECSk5Pp3LkzAwcO5ODBg+5626ZgqYuZ5WNjYx2uLNg+eS6Xnv9aQZ+Exsz6Uw+v+GZk8XBRURF79uyhffv2bpkJ444urrRt3HZAQECF/0eLxXLE4XDEVnS937agAE0jQhmgNOWHvZkczbpotjsSyWX4tUABRqXE4XDA3M1VrR+XSLyP3wu035VNaBoRwhebMrDb6153X1K78XuBBgZYGd4tlsNnLrLuwCmz3ZFILsHvBQowMkVOoJf4JlKgQJvGYfSIb8Q3vxwn+0LNMxdIJO5CCtTJyO5x5BfaWfjzEbNdkUhKkAJ1MqhTc8JDAvlik+zmVkZ8fDyKopCUlES7du0YMmRIyRS+mTNn8sorr7jNVul1oEZITk7m4sWaPTYTQpRMETQVh8NR514xMTGOykhPTy93/5R52x2tH1vi2HE4q9Lra0JFtsujsLDQsWvXLkdhYaFbbOfl5dX4Hq1bt3bs2LGjZHvhwoWOyMhIx/r1691mu6ioyFFUVFRtH2tiuxjAce7cOcPXFRQUXGa7sv8jcNhRyWdZtqClKM62IFtR1xkyZAgPPPAAL730EkIIJk+eDFy+5vPtt98GIDs7m7vvvptOnTqRlJTEn/70J0BvscaMGcOwYcNITk7m2LFjJetAQV/P+eijj9K3b1/i4uJ48cUX+eyzz+jVqxetW7fms89+zydnsVjIyckB9BZ/2rRp9OrVizZt2jBt2rSS86ZPn0737t3p0qULPXr0KFl/et999wHQq1cvkpOTOXnyJCdOnOC2226jU6dOdOzYkXfeeafkPvHx8Tz77LP079+fcePGufXv67erWcojKTaSK5tFsHDrEaYOUgkNMifRVEXcPWsjh05dqPb1jkrWg7aOrs9747pX677du3dn4cKFJCYmluwru+bzxIkTgL6SJTw8nG3btmG1WsnM/L00ycqVK9myZQtNmzYt1056ejqrVq3i+PHjXHHFFUyaNIm1a9eyYcMGhg4dWuHKl6ysLNauXUtmZiYJCQmMHz+emJgYxowZUzLfd/369UyYMIGdO3cyc+ZM3n77bdauXVuyAmbUqFEoisKCBQs4efJkyZdPjx49SnxbsWKF2/NHSYGWwmKxMLJ7HM8s2cW3vxxnSHKM2S7VChzlzOcuu+az+IO8ZMkSNm/eXJLdrnQVultuuaVCcQKMGDECq9VKy5Ytady4MUOHDgWgW7duHDt2jNzcXEJDQy+77o477iix1bZtW3799VdiYmLYunUrzz77LKdOnSIwMJBdu3ZVOG932bJlbNu2DYCmTZsybNgwli9fXvK+xo8f75Hkbmal3WwHzAIaA1nAXapN21XmHCvwb+BGdD/XAPerNs2jI/fbusTw/Ncan2/M8DmBVreFK8ZTk8Y3btxIx44dL9lXds2nqqol3dyKqGq9ZmnxBQQElGwXT0AvXmZW1XWFhYXk5+czfPhwVq1aRbdu3Th79iyRkZGV/o3KCrD0tqfWmpo1Bn0beEe1ae3RRVhevtsJQGegK6A69/3F0441Cgvm+g7NWbv/FOk16E76C4sWLWLGjBmXLQ0ru+azeG3n4MGDefHFF7Hb7QCXdHG9SW5uLgUFBSUri15//fVLjkdERJCdnV2yPXDgwJJxZ2ZmJgsWLGDAgAEe99PrAtUUtSm66D527poHtNEUNb7MqUnAMtWm5Turmy0FxnjDx5HOYFHaZhksKo/U1FSSkpJISEjg/fffZ+nSpVx99dWXnFN2zecLL7wAwCuvvMKFCxdK1n1OnTrVjLdAgwYNePrpp+nRowd9+/YlJOTSGrqTJk1iwIABJUGi1157je3bt9O5c2f69+/PE088UdK99SReXw+qKWo34CPVpnUotW8DMFm1aT+U2jcOuAe9i5sHfALcoNq0BlXZcHU9aEUU2R384YUVOIDVjw0gwOq+sYVcD+p/tmuyHtSsIFHZb4XyFDAbvWDSD8B5YBlQbp/CE9XNrmvXgFmbTrJgrcZVrd2XVMxI7liHw0FhYSEFBQUUFdU8LUtFYzRv4M+27XY7hYWFHDlyxHAgyQyBZgCxmqIGqjatUFNUCxBHmcplzm7t084XmqLeDuwqezMwVt2smKqO3x0WzaxNJ1lx6CKpfdybVMxIC3r+/HmCgoLcVlvErJbEn20HBAQQGBhITEyM4f+j18egqk07CWwF7nTuGg4cVG3awdLnaYoaqilqQ+fvjYEp6AElrxDXqD69E6L5btcJTuXkVX2BROIBzIri3gvcqynqHnThTQDQFPU9TVEHO8+JBNZrivoLsBqYqdq0xd50cmRKHAVFDhZsNWcCfU2K7kh8h+L/X3Wek5pV3Ww30LOc/XeX+v0EoHjTr7LckNicyHpBfLEpgwl92ni9ypjVaiUoKKgkB21N7dvtdreMZaVt1ykqKuLMmTMEBQUZLj0IciZRpYQGBTA0uSWz1h3i54wsurSK8roPrVq1Ij093S2FicwsGuTPtuvVq0erVtUrMSIFWgUju8cxa90hvtiUYYpAg4ODSUhIwG6317ire+TIEWJizJkd5c+2qytOkAKtksSWkXSMacDibcf4v1s6UD/YnD9ZdbpHZbFYLKZVmvZn2zVBLjdzgVEpceTkFfLVdlmuUOJdpEBdYHBSDMGBVtI2ydy5Eu8iBeoCkfWDuKljczYcPM2BzByz3ZH4EVKgLjIqpTjbgmxFJd5DCtRFrm4bTVyjeszbcpjCIrvZ7kj8BClQF7FaLYzsFkfmuTxW7jZnDaPE/5ACNUBqSixWi8xAL/EeUqAGaBFZj77tm7By90lOns012x2JHyAFapBRKXEU2R3M2yIz0Es8jxSoQa5VmxEdFkzapgy5ykTicaRADRIcaOW2LjEc+O08mw6dMdsdSR3HZYFqirpAU9SbnBkQ/JripGIyWCTxNEZa0FjgK+CQpqhCU9TqT9Gv5bRvFkFyXEO+2n6Mc7myXKHEc7gsUNWmdQeSgUXAw8ABTVG/0RR1mKaofrcqZlT3OC4WFLFETqCXeBBDY1DVpm1XbdrDQEtgHBAMfAEc1hT1BU1R23vAR5/kls4tqBcUILu5Eo9SrSCRatPyVJv2CfAP9HxBTYHJgKYp6peaorqWtq4WExEaxM2dW/BzRhZ7Tpwz2x1JHcWwQDVFbaIp6mRNUTVgFXorOh6IAkajl2mY404nfZVRMlgk8TAujx01Rb0BmAjcAuSil24Yqdq0HaVO+1xT1FPowaQ6T0rrKNo2CWPB1iM8dqNCcKB8aiVxL0aCO18DG4EHgM9Um1ZRZaG9wKeV3cjF6mYW9Dy4g4Ai4BQwUbVp+wz47FEsFgsjU+J4/msby7QTDOrUwmyXJHUMI1/5XVWbdpVq0/5biThRbdoh1aaNr+JerlQ3Gwz0BZJVm9YZWA48Z8BfrzCsawwBVousyi3xCEYEul9T1HKbCE1RW2iK6lKBRAPVzQBCgFBna9oA8LnV0k0jQhmgNOWHPZkcy75otjuSOoYRgb4DPFvBsWecx10hDjiq2rRCKKnBkg6UnfiwGFgJHAeOAdcCTxnw12uMTInD7oC5MtuCxM0YGYNegz5BoTyWAq8ZuJcr1c26omeWjwHOAs8DbwB3lT3RE9XNjJAQ5qBR/UA+/ekgg9uFYK0k1aK7bRtB2q59to0ItBF6QKc8stEDPq7gUnUzdCGuVG1aFoCmqLPQvwguwxPVzYwysvsFZn6/nyP59emVUPmfwt22jSBt1y7bRrq4h4BeFRzrg4vjQ1ermwEHgGs1RQ1ybt8K7DTgr1cZmaLXYP1cBoskbsSIQD8FHtcUdXTpnZqi3gn8Hb0Ctqu4Ut3sTfRWdYemqNuB/sCDBmx4lbZNwukR34ivdx4n+4KcQC9xD0a6uM/hjL5qivoeevCmORCKHtB5xtUbuVjdLA99YkStYWT3ODYcPM2ibUcY2zPebHckdQAjq1kKVJs2BLge+A96SfpXgYGqTRtSHJX1ZwZ1ak54SKCc+idxG4aXiak2bRm6OCVlqB8cyK1JLZmzIZ2dR7LpGBNptkuSWk611nFqitoAvWt7Cc4AkF8zqnscczakk7YpQwpUUmOMTJa3oC8vuxd9eVl5mFPjzYdIio3kymYRLPz5KI8PUgkN8vs/iaQGGIniPuJ8vYY+seA59MDQPvRHIrUqoOMpLBYLI1Jiyb5YwLe/HDfbHUktx4hAJwD/RJ/cDrBAtWkCff3nAaCte12rvQzrGktQgJxAL6k5RgTaBtii2rQioBCIBFBtmh19Cl5VK1j8hkZhwVzXoRlr9p0i43SFC38kkioxItAzQH3n70eATqWO1Qci3OVUXWCks1xhmmxFJTXASBR3A5CEvnB7EfAPZza/POAxYK373au9/KFdE1pGhpK2+TB/GdieAKvfpxOWVAMjLejzwH7n7wI9WdgLwOvoLep9bvWslhNgtZDaLZZj2bn8uFeWK5RUD5dbUNWmbUBvRXGuMBmiKWoIEKLatLOeca92MyIljtdW7CNt02H6XVnRkymJpGJcEqimqKHAL8BDqk37uni/c75snod8q/XENapP74Ro/rfrOKfP59MoLNhslyS1DJe6uKpNy0UPAvn9fFujjEyJo6DIwYKtslyhxDhGxqBfAKM85Uhd5YbE5jQIDeSLjbJcocQ4RqK4m4FnNEX9Fj3v7QnKpC5RbdoXbvStThAaFMDQLjHMXneIbYeziTbbIUmtwohAi1NjtgSuK+e4A72VlZRhZEocs9cd4vONGTzQvaHZ7khqEUYE2sZjXtRxOsZEktiyAYu3HWV8cgOz3ZHUIow8ZjnkSUfqOqO6x/HUol9YtT+L9m1bm+2OpJZgZLlZlQV7VZtWNjOfxMmQpBieW6rx0eaTjO1XJJehSVzCSBT3IPBrFS9JBUTWD+KRge3JyMrn1WV7zXZHUkswMga9o5x9jYAb0efo/p9bPKrD3N2nDQs3H+KdH/ZzU8fmJMU1NNsliY9jZAz6eQWHZmiK+hZ6xr+PXLmXi9XNxlIqWzwQC/yg2rRhrvrsawQGWJkyIJaJaft4dO42Fj/ch5BA2dWVVIy7ClrOB8YYOL/K6maqTZut2rTk4hd6fRYjuXd9kiui6/FQ/3bsOZHDmyv3V32BxK9xl0A7odfwrBKD1c2Kr+kBNAO+rJmbvsED/a9AbdGAt1buY9dRuc5AUjFGorh/L2d3MNABGAZ86OKtLqtupilqcXWzgxVcMwH4SLVpdSJle1CAlRdTOzPkzTU8OncbCx/sTVCArM4tuRwjQaLny9mXh14M6SUqLk1YHq5UNwNAU9T66HOAK6oLY3p1MyMU244ERndpwkebT/LvL7cyNsXzy9F84X1L28YwEiRy11e8q9XNikkFtLJBpNL4QnUzIxTbfrJFS9ZlrGbWppOM7NWeds08nzXGF963tO06Xu9XGahuVsyfKCeIVBcICQzgxdTOFNrtPDp3O0V2udpFcikuC1RT1FEVjEPRFPVRTVFHGLDrSnUzNEW9AugGVPSIp9bTpVUUE/q04eeMLP67Ws71kFyKkTHoFPRnl+WR6zye5sqNXKlu5tzejx9kC5x0/ZUs007y0v92M7BDM9o0DjPbJYmPYKSL2w7YXsGxnc7jkmoQGhTAC8M7k1do57G527HLrq7EiRGBFkCF642bcnlkVmKAHm0aMa5nazYcPM1H6+XCIYmOEYGuBR7RFPWSazRFDQD+DKxzp2P+yN9vVIiNqscL39hkRnoJYEygAn0G0E5NUadoijpWU9TH0bu3XZGT5WtMWEggLwzvzIX8IqbM3y5zGEkMVdjeCAwATgPT0GcOPQNkAgOcxyU1pHdCY+7oEceafaf4TFbq9nsMFfBVbdo6oI+mqPWAKOCMatMuesQzP+bxQSqrdmfy7Fca17RvQsuG9cx2SWIS1ZqooNq0i6pNOyrF6RkahAbx3G2dyMkr5IkFO2RX148xMlHhPU1Ry33OqSnq55qivuM+tyT9laYM6xrDyt2ZzN8ik177K0Za0OvQl4aVx3zg+pq7IynNU7d0oHF4CP9c/Asnz+aa7Y7EBIwItBl6suryOAk0r7k7ktI0rB/MtKEdOZtbyJMLd8qurh9iRKDH0XMPlUcX9GiuxM3c2LE5t3Ruwf92neCrHcfMdkfiZYwIdAHwlKaovUvv1BS1D/AEejdX4gH+OTiRRmHBPLXoF07lyGJy/oQRgT6FXsD3B01Rd2uKukJT1N3AD8AB4ElPOCiB6PAQxOBETp/PRyyucFmspA5iZKLCOfSsBvcCW9BLEW5GXyrWHxkk8ii3dm7B9R2asXjbUb795bjZ7ki8hNGJCgXAe84XmqJeA/wReBk9i4fMIekhLBYL04Z2ZP2BUzy5cCdXtWlEw/qyIHBdx/BEBU1RVU1Rn9UU9SCwAl2gS5EtqMdp2iCUp25NJPNcHs8s0cx2R+IFXGpBNUVthp5ZfgyQ7Nz9E3ouoVtVm7bCI95JLmN41xiWbD/KvC2HuSWpBf2v9HyyMYl5VNqCaor6R01Rv0FP9DUdPc3mE0A8MAg9G1+hh32UlMJisfDcbZ0IDwlk6vwdnM2tE5lIJRVQVRf3I/QZRN8BXVSb1km1ac+rNi0DuUDbNFo2rMfUQSrHsnP511Kb2e5IPEhVAl2OLsQbgQ80Rf2bpqgtPe+WpCru6BFHryuimbMhnTX7fjPbHYmHqFSgqk27Dr1o0d/Ru7MvAYc0Rf0OGIdsRU3DYrHwwvDO1AsKYMr87ZzPkyONukiVQSLVph1Hf4zysqaoHYCx6AGjV52nPObM/v6tatNcEqwr1c2c53UCXkefB2wFHldtmpyx5CSuUX0eu/FKxOJdvPjtbsTgRLNdkrgZQ49ZVJu2S7VpU1Sb1hq4FvgA6I3+mMXI8v8qq5s5Rb8QeFK1aSqQCPxoxF9/YGzPeLrHR/Hh2oNs+NW8EgcSz1DtzPKqTVup2rQJ6K3b7eiziqrEQHWz0cA61aatdtorVG2anJBfBqtV7+qGBFp5bN52cgtcKjInqSXUuPSDatPyVJv2hWrThrh4yWXVzdDrsrQqc14HIFdT1CWaov6sKepsTVGb1NTfukjbJuFMur49v/52nunf7THbHYkbMTTVz424Ut0sCLgBuBo4ip6o7E1gZNkTa2N1M3dzfesgFjStx3s/HqBrEyuJzet7zbYrSNvVwwyBulrd7BCwUrVpRwA0Rf0Efax7GbW1upm7+c8fo7jltdW8/ONxlvy5DyGBl0+Nrovvuy7b9uXqZl8A3TVFbeDcvhHY5hUnayntm0Xw52sT2Hsyh9eX7zPbHYkbMKusc5XVzVSblg78C1inKeo2YCDwoEn+1hruveYKOrRowIzv97PzSLbZ7khqiCljUAPVzWYDs73lV10gKMDKiyM6M+SNNTw6dztfPtSboACzvoclNUX+5+ogiS0jeaDfFWjHzjJz1X6z3ZHUACnQOsqDAxJo3yyc11bsZffxc2a741VyC4o4dOo86w+cYtHPR/j5aI7ZLlUbsx6zSDxMSGAA/05NYthba/j73G3Mu7+X2S7VGIfDQfbFAo6fzeVYdi4nsnM5fjaX42V+Zl24fAnerjMWHr3+SqzW8p7o+S5SoHWY5LiGTPxDW97+4QDvr/6VQW19N0VKYZGdzJw8XWTFgisWXXYuJ5zbuQX2cq8PDrTSvEEo7ZtF0LxBKM0jQ2neIJSmDUJ4a/luZqzaz94TObx6ezLhIbXnY197PJVUi79e157vdp3g5e/20GZoW0Ibej9tpwMH6Vl5ZOT/ViK+E9nOVtApvMxzeVRUWDyyXhAtIkO5qk307+JzCrD4Z8P6QVgs5beOSkQBb244w4KtR0idsZZ3x6YQ1+jyiRy+iBRoHSc0KIB/p3ZmxNvruGfuPsB3no8GWC00CQ+hRWQ9usRFXSK8Zg1CaRGp/6wXXLNcdCGBVqaPTKJ9swj+/a2NIW+uYcYfu3JV24oKxvsOUqB+QEp8I94a3ZXvth8iPDzcFB+K8i7QPrYpzZytXovIUBqHhxDgpTGhxWLh/n5X0K5pOH/5bCt3vv8T04Z2ZFT3slPAfQspUD/hpk4t6Niw0LQpbxkZGaZOtytmYIdmzH+gNxNmbeSxeTuwHT/HE4NUAn30WbEUqMTvuLJ5BIse7M39n2zhgzUH2XcyhzdGdyWyXlC55zvsdhz5+Tjy8rDn5em/O7f1ffk48vNKneM8lp9H/slMHH9+GEtw9QJ0UqASl3AUFuofvvx8HLm5l34wiz+4FWzb8/LIO32GzAYNqjbkAfLOnOFEaKjTf6dfeXk8n1/A9JAOLNkLtzyRxrRDXxObk6m/x2Lx5edDQc0yJ9rvmUiAFKikIorOnuXs0q/J+2Unx4NDdNHk5pX6EP7+odUFdekH1JGXB0U1XwhuZmqz8hZ9WYKDeShkE3HxvXi77bU82GYoTx1dQffC37AGB2MJDsYSEoIlJARriHM7OMS5LxhrSAiWoOBLt4NDnNfp2yezsrDWq1dtv6VA6ygOh4OLmzeTlZbG2W++1UUGnClzXvEH0BISjNX54bOGhWGNiir3WMkHMST00g/lJcf0fdaQ3z/gJzIzad7cnBKyx0+coGV8/O/vJzgYS1AQFqs+7lSAnnsyefDTLTwefzP/d7PKuF7xFT62MUJARgaWoPK7zq4gBVrHKDx9muwFC8maO5f8X38FoF7XrjRMTSU7LpaYNm1+/6AGVfzs0N1Y69cnxKQgkTUkhKCYmErP6du+CQsf7M3EWZsQi3ex+0QO/xycSHCgucEjKdA6gMNu5/zadWSlpXFuxQooKCCgYUMajRtHwxGphCQkAHAuI4PAxo1N9tZ3uaJJOAse6M1Dc7YwZ0M6BzJzmHFnNxqFmTcDSwq0FlNw/DhZ8+eTPXceBUePAhDWqycNU1MJHzgQazUDE/5MZP0gPrirO9O+0vhw7UGGvLma98d1p32zCFP8kQKtZTgKCsj5/nuy0uaS8+OPYLcT2LQp0ffdS8Phwwn2gWeNtZ3AACticCLtm0Xw1KKd3PbmGl67owvXqs2874vXLUqqRX56Ollpc8lauICizN/AaiX8mmtoOGIE4X3/gCVQ/ivdzeirWtG2SRj3f7yZu2dv4rEbFe7t29Zr43aQAvVp7Hl5nPtuGVlpaVz46ScAgmJjafTIX4i87TaCmnn/G93fuLptNF8+1IcJszby/Nc29hw/x3PDOhEa5J1a1VKgPkjunj1kzZ3L2UVfUpSdjSUoiAaDbqJhair1r7665PGAxDvENarPvPt78chnPzN/6xF+PXWet8d0o2lEqMdtS4H6CPbz5zn79ddkpc3l4jY9eWHwFVcQff99RA4ZQmBUlMke+jcRoUG8MzaFF7/dzczv9zPkjTW8OzaFjjGRHrUrBWoiDoeD3J07yUqby9klS7BfuIAlNJTI226j4YgR1OuS7NXxjqRyAqwWptyk0L5ZOFPm7SB15lqmj0xmUKcWHrNpikBdqW6mKWo/9ETVpWsZ9FRt2kUvuekxirKzyV68hKy5c8mz6QV4QxMTaTgilQY330xAhDkhfYlrDOsaS3zjMO6ZvZkHPtnCIwPb8ecB7TySTsWsFrS4utmHmqKmolc3uywNJ7BLtWkp3nXNMxRPvcv94EP2rl6NIy8Pa3g4UaPvoGFqKqEdOpjtosQAXVtF8eVDvZk4exOvLtvL3hM5vDQiqcaLy8vidYGWqm52vXPXPOANTVHjy8kuX+ux5+ZydskSTn/8SUlrWa9bN721vOGGGk2klphLy4b1SLuvJ5PTtvHVjmMcPHWed8em0LKh+/6nZrSgl1U30xS1uLrZwTLnXqkp6hagCPhAtWlvedXTGlBw9Chn5swh64s0irKzsYaFEXXnneT160frPr3Ndk/iJuoHB/LGHV15rdleXl22l8FvrOGdsd3o2so9QT1frm62BYhVbVq2pqixwFJNUX9TbdoXZU/0lepmDocD+/Yd5C9aSNGatWC3Y4mNJfjOPxJ03XUUhIWRdfo01kp88yS1ucqXr9sefmU9GgW04tnlGdz+9joe7R/LjVdG1d3qZqpNO1vq98Oaos4B/oBeVOkSzK5uZr94kewlSzjz8Sfk7d4NQFjfP9BozBjCeve+7Lllba20JW1Xzti4OLq2b8XE2Zt4dlkGpwqCub1DVI1se12gqk07qSlqcXWzD6mgupmmqC2AE6pNs2uKGgHcgh5M8hnK7caOGUPU6DsIadPGbPckJtAxJpJFD/Xm3o82M/P7/ew4FMHb41tWOxevWV3ce4EPNUWdCpwFxoFe3Qz4UrVpX6IL935NUQudfqYBH5jkbwkOh4MLGzZy5uOPObd8OdjtBMfH0/jhh4kcOoQAk7LmSXyHphGhzJl4NVPn72CV7QRnLxbULoG6Ut1MtWlvAG9406/KKOnGfvQxeXv0R7Nh1/Sl0Z13ltuNlfg3oUEBvDwyia22X2sU1ZUziaqg4MgRzsyZw5m0udiLu7Fjx9Bo9GiC4+PNdk/iw1gsFpqEVz/dCUiBlsvv3diPOLd8hd6NbdOGqIcfJnLoUALCw8x2UeInSIGWwn7xItmLF+vd2L17AQi/5hqi7ryTsN69ZDdW4nWkQIH8w0c4M+dTsubO07ux4eGyGyvxCfxWoA6Hgws//cTpjz8mZ8XK37uxf36YyCGyGyvxDfxOoPYLFyhYsoRfly4lb+8+sFgI79uXqDFjCOvVU3ZjJT6FXwk0b/9+Dt4xGvvZs1jDw2k0bixRo0cT3Lq12a5JJOXiVwINjo+nXlIShclJxN91F9Yw2Y2V+DZ+JVBLQACt3n2HjIwMKU5JrUAOuCQSH0YKVCLxYaRAJRIfRgpUIvFhpEAlEh9GClQi8WEsDkfZ9EC1H4vFkgdkVnJKOJDjJXekbWm7MttNHA5HSEUH66RAq8JisRx2OByx0ra07eu2ZRdXIvFhpEAlEh/GXwU6vepTpG1p23zbfjkGlUhqC/7agkoktQIpUInEh5EClUh8GL9aDyqEmAL8GWgILAPuEUIc94LdYcCDQArQAAgSQhR62q7T9lQgFWgPnAO+Af4uhKhsIoe7bE8B7kKvXHcRWANMFkLsqew6D/myEBgCXCeEWOZhWwL4R5ndi4QQQ43ey29aUCHEeOBJ4CGgF7pQPveS+frACuB5L9krTR/0SGIK+ge0A9573/vR/96JwAD0MpJfecl2Cc7/vbcLsW4AWpR63VWdm/hNFFcIsQX4WgjxhHO7LfoHqIsQ4mcv+dAPWIkXW9ByfOgJrAUaCiGyvWy7E7AdaC6EOOElm62BH9G/lDPwXgs6UAjRp6b38osWVAgRAiSht2LF+w6gFwy+yiS3zKIxkAuc96ZRIUQ99FZkN5XPk3anTSswC/iHEOKwN2yWIkkIcVwIsUcI8aYQoloVff1CoEA0+ns9WWZ/JtDU++6Yg/OL6ilglhfHwLcIIXLQvxBuBm4SQti9YRv4K5AjhPB2Vbz1wFjgOmAScA36GLS8QtWV4i9BIsN/mLqGECIA+Ni5OdmLplcCyUBz9A/rHCHEH4QQBZ40KoRQnfZSPGmnAtvflNrcIYTYBewDugGbjNzLX1rQ3wA7l7eWTbi8Va1zOLt6HwIKcIOzRfOW7fNCiH1CiNXAKKATcJMXTF+F/qWQLoQoLNVj+FYI8YkX7JcghNgPZAGGqzr7hUCFEHnANqB/qX1tgHjgJ5Pc8grObtV7wNXoAZLTJrtkAbzRvV4IdEZvvYtfoBePfswL9ksQQrRCf7R30Oi1/tLFBb0Y8H+EEJuBA8ArwI/eiOAKIRqhPwtMcO5KEkIUAfu80JrNBG5FH/8hhGju3J/p9MFjCCFeQBfKUaAZMAW9N7PGk3adtrPQW63S+wAOejpgJIT4N/AlcBi91XwRWAdsNnovv2hBAYQQ/wWeA95CH8SfB0Z6yfxgYCvwrnN7k3PbG+Oje9Ajtz8Bx0q94rxguxWQBuwB5gN5wLXefrxjAq35/X1/gC7MIdUJjvnNc1CJpDbiNy2oRFIbkQKVSHwYKVCJxIeRApVIfBgpUInEh5EClUh8GH+aqOC3CCGuR1+ofhUQib5IYDnwshBimxvtrAJyhRA3uuue/o5sQes4Qoh/AN+iz0V+CBiIPlk+An2yhMSHkS1oHcbZcgrgRSHE38scniOEuNX7XkmMIAVat3kUfbXOk+UdFEIsFkL8FX0KZEshxJlSxxqhz6F9XAjxinNfe2AaevqSMPTJ3zOFEP+pyAEhxJXO+w8AQtGnWf7VW1ksajuyi1tHEUIEoucjWiaEyK/k1FnOn2PK7B+DvvJktvN+V6DP5+2Evs7yZuA1oMLCQEKIePT0KjHoc4JT0bvaq4QQTYy9I/9EtqB1l2j0Fiu9spOEEKeFEHOBCeiCK2YCsEAIccq5/U90cfV0rhSBUilkKro9+qKEa4UQ5532VqDngpqEvrpFUgmyBa27FGeRcGU1xNtAZyFEDwAhxFXoLeW7pc4ZCMwvJU5XuB592VWeECLQ2aoXAKuBHgbu47dIgdZdfkNPDtaqqhOd2Q5+Ae527robfc1s6RYyGjhi0Icm6PmAC8q8Rrjil0QKtM7iTPHxI3r6xyAXLnkHuF0I0Qw9Ncn7QojSre9v6GNJI5xCH8N2L+d1m8F7+SVyDFq3eQn9GejTwONlDzoz7i1xbs5GT6z9OXqS57KZ8JYBw4QQjxro5v4PPe3Iz97KIljXkAu26zhClJQhWAR8AhwHWqJHVIc7E4oVn/shMI5yyhQ4o7ibnNc/jx58SgDaFT9jLTuTyBnF3QjsQk+9chQ9cdvVwCEhROmglKQcZBe3juMU6I1AEDADfVw5HX0s2KvM6fOdP98r5z77gZ6ABrwKLEXPO5tRie2D6MGgDOc1/0Nv1WPRSyNIqkC2oJIShBAzgFuAeE8nFJO4hhyDShB6zZROwHjg/6Q4fQcpUAnAYvSx4Tygwml7Eu8ju7gSiQ8jg0QSiQ8jBSqR+DBSoBKJDyMFKpH4MFKgEokPIwUqkfgwUqASiQ/z/yHpzn0uxnQ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 240x240 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634bd3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8e281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
